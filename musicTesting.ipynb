{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#RNN Text Generation (Romeo and Juliet play generator)\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ImperialMarch.csv') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 479, 0, 55, 0], [2, 479, 0, 43, 0], [2, 480, 0, 55, 64], [2, 480, 0, 43, 64], [2, 719, 0, 55, 0], [2, 720, 0, 55, 64], [2, 799, 0, 55, 0], [2, 800, 0, 55, 64], [2, 879, 0, 55, 0], [2, 880, 0, 55, 64], [2, 959, 0, 43, 0], [2, 959, 0, 55, 0], [2, 960, 0, 55, 64], [2, 960, 0, 43, 64], [2, 1199, 0, 55, 0], [2, 1200, 0, 55, 64], [2, 1319, 0, 55, 0], [2, 1320, 0, 55, 64], [2, 1439, 0, 43, 0], [2, 1439, 0, 55, 0], [2, 1440, 0, 54, 64], [2, 1440, 0, 39, 64], [2, 1559, 0, 54, 0], [2, 1560, 0, 54, 64], [2, 1679, 0, 54, 0], [2, 1680, 0, 54, 64], [2, 1919, 0, 39, 0], [2, 1919, 0, 54, 0], [2, 1920, 0, 55, 64], [2, 1920, 0, 43, 64], [2, 2399, 0, 55, 0], [2, 2399, 0, 43, 0], [2, 2400, 0, 55, 64], [2, 2400, 0, 43, 64], [2, 2639, 0, 55, 0], [2, 2640, 0, 55, 64], [2, 2719, 0, 55, 0], [2, 2720, 0, 55, 64], [2, 2799, 0, 55, 0], [2, 2800, 0, 55, 64], [2, 2879, 0, 43, 0], [2, 2879, 0, 55, 0], [2, 2880, 0, 55, 64], [2, 2880, 0, 43, 64], [2, 3119, 0, 55, 0], [2, 3120, 0, 55, 64], [2, 3239, 0, 55, 0], [2, 3240, 0, 55, 64], [2, 3359, 0, 43, 0], [2, 3359, 0, 55, 0], [2, 3360, 0, 54, 64], [2, 3360, 0, 39, 64], [2, 3479, 0, 54, 0], [2, 3480, 0, 54, 64], [2, 3599, 0, 54, 0], [2, 3600, 0, 54, 64], [2, 3839, 0, 39, 0], [2, 3839, 0, 54, 0], [2, 3840, 0, 55, 64], [2, 3840, 0, 43, 64], [2, 4319, 0, 55, 0], [2, 4319, 0, 43, 0], [2, 4320, 0, 55, 64], [2, 4320, 0, 43, 64], [2, 4559, 0, 55, 0], [2, 4560, 0, 55, 64], [2, 4639, 0, 55, 0], [2, 4640, 0, 55, 64], [2, 4719, 0, 55, 0], [2, 4720, 0, 55, 64], [2, 4799, 0, 43, 0], [2, 4799, 0, 55, 0], [2, 4800, 0, 55, 64], [2, 4800, 0, 43, 64], [2, 5039, 0, 55, 0], [2, 5040, 0, 55, 64], [2, 5159, 0, 55, 0], [2, 5160, 0, 55, 64], [2, 5279, 0, 43, 0], [2, 5279, 0, 55, 0], [2, 5280, 0, 54, 64], [2, 5280, 0, 39, 64], [2, 5399, 0, 54, 0], [2, 5400, 0, 54, 64], [2, 5519, 0, 54, 0], [2, 5520, 0, 54, 64], [2, 5759, 0, 39, 0], [2, 5759, 0, 54, 0], [2, 5760, 0, 55, 64], [2, 5760, 0, 43, 64], [2, 6239, 0, 55, 0], [2, 6239, 0, 43, 0], [2, 6240, 0, 55, 64], [2, 6240, 0, 43, 64], [2, 6479, 0, 55, 0], [2, 6480, 0, 55, 64], [2, 6559, 0, 55, 0], [2, 6560, 0, 55, 64], [2, 6639, 0, 55, 0], [2, 6640, 0, 55, 64], [2, 6719, 0, 43, 0], [2, 6719, 0, 55, 0], [2, 6720, 0, 55, 64], [2, 6720, 0, 43, 64], [2, 6959, 0, 55, 0], [2, 6960, 0, 55, 64], [2, 7079, 0, 55, 0], [2, 7080, 0, 55, 64], [2, 7199, 0, 43, 0], [2, 7199, 0, 55, 0], [2, 7200, 0, 54, 64], [2, 7200, 0, 39, 64], [2, 7319, 0, 54, 0], [2, 7320, 0, 54, 64], [2, 7439, 0, 54, 0], [2, 7440, 0, 54, 64], [2, 7679, 0, 39, 0], [2, 7679, 0, 54, 0], [2, 7680, 0, 43, 96], [2, 7680, 0, 50, 96], [2, 7680, 0, 55, 96], [2, 8159, 0, 43, 0], [2, 8159, 0, 50, 0], [2, 8159, 0, 55, 0], [2, 8160, 0, 43, 96], [2, 8160, 0, 50, 96], [2, 8160, 0, 55, 96], [2, 8639, 0, 43, 0], [2, 8639, 0, 50, 0], [2, 8639, 0, 55, 0], [2, 8640, 0, 43, 96], [2, 8640, 0, 50, 96], [2, 8640, 0, 55, 96], [2, 9119, 0, 43, 0], [2, 9119, 0, 50, 0], [2, 9119, 0, 55, 0], [2, 9120, 0, 42, 96], [2, 9120, 0, 51, 96], [2, 9120, 0, 54, 96], [2, 9599, 0, 42, 0], [2, 9599, 0, 51, 0], [2, 9599, 0, 54, 0], [2, 9600, 0, 43, 96], [2, 9600, 0, 50, 96], [2, 9600, 0, 55, 96], [2, 10079, 0, 43, 0], [2, 10079, 0, 50, 0], [2, 10079, 0, 55, 0], [2, 10080, 0, 42, 96], [2, 10080, 0, 51, 96], [2, 10080, 0, 54, 96], [2, 10559, 0, 42, 0], [2, 10559, 0, 51, 0], [2, 10559, 0, 54, 0], [2, 10560, 0, 43, 96], [2, 10560, 0, 50, 96], [2, 10560, 0, 55, 96], [2, 10800, 0, 55, 96], [2, 10919, 0, 55, 0], [2, 10920, 0, 55, 96], [2, 11039, 0, 55, 0], [2, 11040, 0, 55, 96], [2, 11159, 0, 55, 0], [2, 11160, 0, 55, 96], [2, 11279, 0, 55, 0], [2, 11280, 0, 55, 96], [2, 11519, 0, 43, 0], [2, 11519, 0, 50, 0], [2, 11519, 0, 55, 0], [2, 11519, 0, 55, 0], [2, 11520, 0, 43, 96], [2, 11520, 0, 50, 96], [2, 11520, 0, 55, 96], [2, 11999, 0, 43, 0], [2, 11999, 0, 50, 0], [2, 11999, 0, 55, 0], [2, 12000, 0, 43, 96], [2, 12000, 0, 50, 96], [2, 12000, 0, 55, 96], [2, 12479, 0, 43, 0], [2, 12479, 0, 50, 0], [2, 12479, 0, 55, 0], [2, 12480, 0, 43, 96], [2, 12480, 0, 50, 96], [2, 12480, 0, 55, 96], [2, 12959, 0, 43, 0], [2, 12959, 0, 50, 0], [2, 12959, 0, 55, 0], [2, 12960, 0, 42, 96], [2, 12960, 0, 51, 96], [2, 12960, 0, 54, 96], [2, 13439, 0, 42, 0], [2, 13439, 0, 51, 0], [2, 13439, 0, 54, 0], [2, 13440, 0, 39, 96], [2, 13440, 0, 46, 96], [2, 13440, 0, 51, 96], [2, 13919, 0, 39, 0], [2, 13919, 0, 46, 0], [2, 13919, 0, 51, 0], [2, 13920, 0, 36, 96], [2, 13920, 0, 43, 96], [2, 13920, 0, 48, 96], [2, 14399, 0, 36, 0], [2, 14399, 0, 43, 0], [2, 14399, 0, 48, 0], [2, 14400, 0, 43, 96], [2, 14400, 0, 50, 96], [2, 14400, 0, 55, 96], [2, 14640, 0, 55, 96], [2, 14759, 0, 55, 0], [2, 14760, 0, 55, 96], [2, 14879, 0, 55, 0], [2, 14880, 0, 55, 96], [2, 14999, 0, 55, 0], [2, 15000, 0, 55, 96], [2, 15119, 0, 55, 0], [2, 15120, 0, 55, 96], [2, 15359, 0, 43, 0], [2, 15359, 0, 50, 0], [2, 15359, 0, 55, 0], [2, 15359, 0, 55, 0], [2, 15360, 0, 43, 96], [2, 15360, 0, 50, 96], [2, 15360, 0, 55, 96], [2, 15839, 0, 43, 0], [2, 15839, 0, 50, 0], [2, 15839, 0, 55, 0], [2, 15840, 0, 43, 96], [2, 15840, 0, 50, 96], [2, 15840, 0, 55, 96], [2, 16319, 0, 43, 0], [2, 16319, 0, 50, 0], [2, 16319, 0, 55, 0], [2, 16320, 0, 43, 96], [2, 16320, 0, 50, 96], [2, 16320, 0, 55, 96], [2, 16799, 0, 43, 0], [2, 16799, 0, 50, 0], [2, 16799, 0, 55, 0], [2, 16800, 0, 43, 96], [2, 16800, 0, 50, 96], [2, 16800, 0, 55, 96], [2, 17279, 0, 43, 0], [2, 17279, 0, 50, 0], [2, 17279, 0, 55, 0], [2, 17280, 0, 37, 96], [2, 17280, 0, 44, 96], [2, 17280, 0, 49, 96], [2, 17759, 0, 37, 0], [2, 17759, 0, 44, 0], [2, 17759, 0, 49, 0], [2, 17760, 0, 37, 96], [2, 17760, 0, 44, 96], [2, 17760, 0, 49, 96], [2, 18239, 0, 37, 0], [2, 18239, 0, 44, 0], [2, 18239, 0, 49, 0], [2, 18240, 0, 37, 96], [2, 18240, 0, 44, 96], [2, 18240, 0, 49, 96], [2, 18719, 0, 37, 0], [2, 18719, 0, 44, 0], [2, 18719, 0, 49, 0], [2, 18720, 0, 37, 96], [2, 18720, 0, 44, 96], [2, 18720, 0, 49, 96], [2, 19199, 0, 37, 0], [2, 19199, 0, 44, 0], [2, 19199, 0, 49, 0], [2, 19200, 0, 39, 96], [2, 19200, 0, 46, 96], [2, 19200, 0, 51, 96], [2, 19679, 0, 39, 0], [2, 19679, 0, 46, 0], [2, 19679, 0, 51, 0], [2, 19680, 0, 39, 96], [2, 19680, 0, 46, 96], [2, 19680, 0, 51, 96], [2, 20159, 0, 39, 0], [2, 20159, 0, 46, 0], [2, 20159, 0, 51, 0], [2, 20160, 0, 36, 96], [2, 20160, 0, 43, 96], [2, 20160, 0, 48, 96], [2, 20639, 0, 36, 0], [2, 20639, 0, 43, 0], [2, 20639, 0, 48, 0], [2, 20640, 0, 39, 96], [2, 20640, 0, 46, 96], [2, 20640, 0, 51, 96], [2, 21119, 0, 39, 0], [2, 21119, 0, 46, 0], [2, 21119, 0, 51, 0], [2, 21120, 0, 43, 96], [2, 21120, 0, 50, 96], [2, 21120, 0, 55, 96], [2, 21599, 0, 43, 0], [2, 21599, 0, 50, 0], [2, 21599, 0, 55, 0], [2, 21600, 0, 39, 96], [2, 21600, 0, 46, 96], [2, 21600, 0, 51, 96], [2, 22079, 0, 39, 0], [2, 22079, 0, 46, 0], [2, 22079, 0, 51, 0], [2, 22080, 0, 43, 96], [2, 22080, 0, 50, 96], [2, 22080, 0, 55, 96], [2, 22559, 0, 43, 0], [2, 22559, 0, 50, 0], [2, 22559, 0, 55, 0], [2, 22560, 0, 43, 96], [2, 22560, 0, 50, 96], [2, 22560, 0, 55, 96], [2, 23039, 0, 43, 0], [2, 23039, 0, 50, 0], [2, 23039, 0, 55, 0], [2, 23040, 0, 39, 96], [2, 23040, 0, 46, 96], [2, 23040, 0, 51, 96], [2, 23519, 0, 39, 0], [2, 23519, 0, 46, 0], [2, 23519, 0, 51, 0], [2, 23520, 0, 39, 96], [2, 23520, 0, 46, 96], [2, 23520, 0, 51, 96], [2, 23999, 0, 39, 0], [2, 23999, 0, 46, 0], [2, 23999, 0, 51, 0], [2, 24000, 0, 43, 96], [2, 24000, 0, 50, 96], [2, 24000, 0, 55, 96], [2, 24479, 0, 43, 0], [2, 24479, 0, 50, 0], [2, 24479, 0, 55, 0], [2, 24480, 0, 43, 96], [2, 24480, 0, 50, 96], [2, 24480, 0, 55, 96], [2, 24959, 0, 43, 0], [2, 24959, 0, 50, 0], [2, 24959, 0, 55, 0], [2, 24960, 0, 37, 96], [2, 24960, 0, 44, 96], [2, 24960, 0, 49, 96], [2, 25439, 0, 37, 0], [2, 25439, 0, 44, 0], [2, 25439, 0, 49, 0], [2, 25440, 0, 37, 96], [2, 25440, 0, 44, 96], [2, 25440, 0, 49, 96], [2, 25919, 0, 37, 0], [2, 25919, 0, 44, 0], [2, 25919, 0, 49, 0], [2, 25920, 0, 37, 96], [2, 25920, 0, 44, 96], [2, 25920, 0, 49, 96], [2, 26399, 0, 37, 0], [2, 26399, 0, 44, 0], [2, 26399, 0, 49, 0], [2, 26400, 0, 37, 96], [2, 26400, 0, 44, 96], [2, 26400, 0, 49, 96], [2, 26879, 0, 37, 0], [2, 26879, 0, 44, 0], [2, 26879, 0, 49, 0], [2, 26880, 0, 39, 96], [2, 26880, 0, 46, 96], [2, 26880, 0, 51, 96], [2, 27359, 0, 39, 0], [2, 27359, 0, 46, 0], [2, 27359, 0, 51, 0], [2, 27360, 0, 39, 96], [2, 27360, 0, 46, 96], [2, 27360, 0, 51, 96], [2, 27839, 0, 39, 0], [2, 27839, 0, 46, 0], [2, 27839, 0, 51, 0], [2, 27840, 0, 39, 96], [2, 27840, 0, 46, 96], [2, 27840, 0, 51, 96], [2, 28319, 0, 39, 0], [2, 28319, 0, 46, 0], [2, 28319, 0, 51, 0], [2, 28320, 0, 36, 96], [2, 28320, 0, 43, 96], [2, 28320, 0, 48, 96], [2, 28799, 0, 36, 0], [2, 28799, 0, 43, 0], [2, 28799, 0, 48, 0], [2, 28800, 0, 43, 96], [2, 28800, 0, 50, 96], [2, 28800, 0, 55, 96], [2, 29279, 0, 43, 0], [2, 29279, 0, 50, 0], [2, 29279, 0, 55, 0], [2, 29280, 0, 42, 96], [2, 29280, 0, 46, 96], [2, 29280, 0, 51, 96], [2, 29280, 0, 54, 96], [2, 29759, 0, 42, 0], [2, 29759, 0, 46, 0], [2, 29759, 0, 51, 0], [2, 29759, 0, 54, 0], [2, 29760, 0, 43, 96], [2, 29760, 0, 50, 96], [2, 29760, 0, 55, 96], [2, 30239, 0, 43, 0], [2, 30239, 0, 50, 0], [2, 30239, 0, 55, 0], [2, 30240, 0, 43, 96], [2, 30240, 0, 50, 96], [2, 30240, 0, 55, 96], [2, 30719, 0, 43, 0], [2, 30719, 0, 50, 0], [2, 30719, 0, 55, 0], [2, 30720, 0, 55, 80], [2, 30720, 0, 43, 80], [2, 31199, 0, 55, 0], [2, 31199, 0, 43, 0], [2, 31200, 0, 55, 80], [2, 31200, 0, 43, 80], [2, 31439, 0, 55, 0], [2, 31440, 0, 55, 80], [2, 31519, 0, 55, 0], [2, 31520, 0, 55, 80], [2, 31599, 0, 55, 0], [2, 31600, 0, 55, 80], [2, 31679, 0, 43, 0], [2, 31679, 0, 55, 0], [2, 31680, 0, 55, 80], [2, 31680, 0, 43, 80], [2, 31919, 0, 55, 0], [2, 31920, 0, 55, 80], [2, 32039, 0, 55, 0], [2, 32040, 0, 55, 80], [2, 32159, 0, 43, 0], [2, 32159, 0, 55, 0], [2, 32160, 0, 54, 80], [2, 32160, 0, 39, 80], [2, 32279, 0, 54, 0], [2, 32280, 0, 54, 80], [2, 32399, 0, 54, 0], [2, 32400, 0, 54, 80], [2, 32639, 0, 39, 0], [2, 32639, 0, 54, 0], [2, 32640, 0, 55, 80], [2, 32640, 0, 43, 80], [2, 33119, 0, 55, 0], [2, 33119, 0, 43, 0], [2, 33120, 0, 55, 80], [2, 33120, 0, 43, 80], [2, 33359, 0, 55, 0], [2, 33360, 0, 55, 80], [2, 33439, 0, 55, 0], [2, 33440, 0, 55, 80], [2, 33519, 0, 55, 0], [2, 33520, 0, 55, 80], [2, 33599, 0, 43, 0], [2, 33599, 0, 55, 0], [2, 33600, 0, 55, 80], [2, 33600, 0, 43, 80], [2, 33839, 0, 55, 0], [2, 33840, 0, 55, 80], [2, 33959, 0, 55, 0], [2, 33960, 0, 55, 80], [2, 34079, 0, 43, 0], [2, 34079, 0, 55, 0], [2, 34080, 0, 54, 80], [2, 34080, 0, 39, 80], [2, 34199, 0, 54, 0], [2, 34200, 0, 54, 80], [2, 34319, 0, 54, 0], [2, 34320, 0, 54, 80], [2, 34559, 0, 39, 0], [2, 34559, 0, 54, 0], [2, 34560, 0, 43, 80], [2, 34560, 0, 50, 80], [2, 35039, 0, 43, 0], [2, 35039, 0, 50, 0], [2, 35040, 0, 43, 80], [2, 35040, 0, 50, 80], [2, 35519, 0, 43, 0], [2, 35519, 0, 50, 0], [2, 35520, 0, 43, 80], [2, 35520, 0, 50, 80], [2, 35999, 0, 43, 0], [2, 35999, 0, 50, 0], [2, 36000, 0, 39, 96], [2, 36000, 0, 46, 96], [2, 36479, 0, 39, 0], [2, 36479, 0, 46, 0], [2, 36480, 0, 43, 96], [2, 36480, 0, 50, 96], [2, 36480, 0, 55, 96], [2, 36959, 0, 43, 0], [2, 36959, 0, 50, 0], [2, 36959, 0, 55, 0], [2, 36960, 0, 43, 100], [2, 36960, 0, 50, 100], [2, 36960, 0, 57, 100], [2, 37439, 0, 43, 0], [2, 37439, 0, 50, 0], [2, 37439, 0, 57, 0], [2, 37440, 0, 43, 105], [2, 37440, 0, 50, 105], [2, 37440, 0, 58, 105], [2, 37919, 0, 43, 0], [2, 37919, 0, 50, 0], [2, 37919, 0, 58, 0], [2, 37920, 0, 43, 109], [2, 37920, 0, 50, 109], [2, 37920, 0, 54, 109], [2, 38399, 0, 43, 0], [2, 38399, 0, 50, 0], [2, 38399, 0, 54, 0], [2, 38400, 0, 55, 33], [2, 38639, 0, 55, 0], [2, 39360, 0, 55, 33], [2, 39599, 0, 55, 0], [2, 40320, 0, 55, 33], [2, 40559, 0, 55, 0], [2, 41280, 0, 55, 33], [2, 41519, 0, 55, 0], [2, 41760, 0, 55, 33], [2, 41999, 0, 55, 0], [2, 42240, 0, 55, 33], [2, 42479, 0, 55, 0], [2, 43200, 0, 55, 33], [2, 43439, 0, 55, 0], [2, 44160, 0, 55, 33], [2, 44399, 0, 55, 0], [2, 45120, 0, 55, 33], [2, 45359, 0, 55, 0], [2, 46080, 0, 43, 49], [2, 46319, 0, 43, 0], [2, 46320, 0, 50, 49], [2, 46559, 0, 50, 0], [2, 46560, 0, 51, 49], [2, 46799, 0, 51, 0], [2, 46800, 0, 48, 49], [2, 47039, 0, 48, 0], [2, 47040, 0, 43, 49], [2, 47279, 0, 43, 0], [2, 48000, 0, 43, 49], [2, 48239, 0, 43, 0], [2, 48960, 0, 43, 49], [2, 49199, 0, 43, 0], [2, 49440, 0, 43, 59], [2, 49679, 0, 43, 0], [2, 49920, 0, 44, 64], [2, 50159, 0, 44, 0], [2, 50880, 0, 44, 64], [2, 51119, 0, 44, 0], [2, 51840, 0, 44, 64], [2, 52079, 0, 44, 0], [2, 52800, 0, 33, 64], [2, 52800, 0, 45, 64], [2, 53039, 0, 33, 0], [2, 53039, 0, 45, 0], [2, 53760, 0, 45, 80], [2, 53760, 0, 57, 80], [2, 54239, 0, 45, 0], [2, 54239, 0, 57, 0], [2, 54240, 0, 45, 80], [2, 54240, 0, 57, 80], [2, 54719, 0, 45, 0], [2, 54719, 0, 57, 0], [2, 54720, 0, 45, 80], [2, 54720, 0, 57, 80], [2, 55199, 0, 45, 0], [2, 55199, 0, 57, 0], [2, 55200, 0, 41, 80], [2, 55200, 0, 53, 80], [2, 55559, 0, 41, 0], [2, 55559, 0, 53, 0], [2, 55560, 0, 48, 80], [2, 55560, 0, 60, 80], [2, 55679, 0, 48, 0], [2, 55679, 0, 60, 0], [2, 55680, 0, 45, 80], [2, 55680, 0, 57, 80], [2, 56159, 0, 45, 0], [2, 56159, 0, 57, 0], [2, 56160, 0, 41, 80], [2, 56160, 0, 53, 80], [2, 56519, 0, 41, 0], [2, 56519, 0, 53, 0], [2, 56520, 0, 48, 80], [2, 56520, 0, 60, 80], [2, 56639, 0, 48, 0], [2, 56639, 0, 60, 0], [2, 56640, 0, 45, 80], [2, 56640, 0, 57, 80], [2, 60479, 0, 45, 0], [2, 60479, 0, 57, 0], [2, 60480, 0, 52, 80], [2, 60480, 0, 64, 80], [2, 60959, 0, 52, 0], [2, 60959, 0, 64, 0], [2, 60960, 0, 52, 80], [2, 60960, 0, 64, 80], [2, 61439, 0, 52, 0], [2, 61439, 0, 64, 0], [2, 61440, 0, 64, 80], [2, 61440, 0, 48, 80], [2, 61919, 0, 64, 0], [2, 61919, 0, 48, 0], [2, 61920, 0, 65, 80], [2, 61920, 0, 44, 80], [2, 62279, 0, 65, 0], [2, 62280, 0, 60, 80], [2, 62399, 0, 44, 0], [2, 62399, 0, 60, 0], [2, 62400, 0, 56, 80], [2, 62400, 0, 41, 80], [2, 62879, 0, 56, 0], [2, 62879, 0, 41, 0], [2, 62880, 0, 53, 80], [2, 62880, 0, 38, 80], [2, 63239, 0, 53, 0], [2, 63240, 0, 60, 80], [2, 63359, 0, 38, 0], [2, 63359, 0, 60, 0], [2, 63360, 0, 45, 80], [2, 63360, 0, 57, 80], [2, 67199, 0, 45, 0], [2, 67199, 0, 57, 0], [2, 67200, 0, 58, 80], [2, 67200, 0, 70, 80], [2, 67679, 0, 58, 0], [2, 67679, 0, 70, 0], [2, 67680, 0, 46, 80], [2, 67680, 0, 58, 80], [2, 68039, 0, 46, 0], [2, 68039, 0, 58, 0], [2, 68040, 0, 46, 80], [2, 68040, 0, 58, 80], [2, 68159, 0, 46, 0], [2, 68159, 0, 58, 0], [2, 68160, 0, 58, 80], [2, 68160, 0, 70, 80], [2, 68639, 0, 58, 0], [2, 68639, 0, 70, 0], [2, 68640, 0, 57, 80], [2, 68640, 0, 69, 80], [2, 68999, 0, 57, 0], [2, 68999, 0, 69, 0], [2, 69000, 0, 56, 80], [2, 69000, 0, 68, 80], [2, 69119, 0, 56, 0], [2, 69119, 0, 68, 0], [2, 69120, 0, 55, 80], [2, 69120, 0, 67, 80], [2, 69239, 0, 55, 0], [2, 69239, 0, 67, 0], [2, 69240, 0, 54, 80], [2, 69240, 0, 66, 80], [2, 69359, 0, 54, 0], [2, 69359, 0, 66, 0], [2, 69360, 0, 55, 80], [2, 69360, 0, 67, 80], [2, 69479, 0, 55, 0], [2, 69479, 0, 67, 0], [2, 69840, 0, 47, 80], [2, 69840, 0, 59, 80], [2, 70079, 0, 47, 0], [2, 70079, 0, 59, 0], [2, 70080, 0, 52, 80], [2, 70080, 0, 64, 80], [2, 71759, 0, 52, 0], [2, 71759, 0, 64, 0], [2, 72480, 0, 51, 80], [2, 72480, 0, 63, 80], [2, 72839, 0, 51, 0], [2, 72839, 0, 63, 0], [2, 72840, 0, 50, 80], [2, 72840, 0, 62, 80], [2, 72959, 0, 50, 0], [2, 72959, 0, 62, 0], [2, 72960, 0, 49, 80], [2, 72960, 0, 61, 80], [2, 73079, 0, 49, 0], [2, 73079, 0, 61, 0], [2, 73080, 0, 48, 80], [2, 73080, 0, 60, 80], [2, 73199, 0, 48, 0], [2, 73199, 0, 60, 0], [2, 73200, 0, 49, 80], [2, 73200, 0, 61, 80], [2, 73319, 0, 49, 0], [2, 73319, 0, 61, 0], [2, 73680, 0, 42, 80], [2, 73680, 0, 54, 80], [2, 73919, 0, 42, 0], [2, 73919, 0, 54, 0], [2, 73920, 0, 45, 80], [2, 73920, 0, 57, 80], [2, 75839, 0, 45, 0], [2, 75839, 0, 57, 0], [2, 75840, 0, 42, 80], [2, 75840, 0, 54, 80], [2, 76319, 0, 42, 0], [2, 76319, 0, 54, 0], [2, 76320, 0, 49, 80], [2, 76320, 0, 61, 80], [2, 76799, 0, 49, 0], [2, 76799, 0, 61, 0], [2, 76800, 0, 46, 80], [2, 76800, 0, 58, 80], [2, 77279, 0, 46, 0], [2, 77279, 0, 58, 0], [2, 77280, 0, 42, 80], [2, 77280, 0, 54, 80], [2, 77639, 0, 42, 0], [2, 77639, 0, 54, 0], [2, 77640, 0, 49, 80], [2, 77640, 0, 61, 80], [2, 77759, 0, 49, 0], [2, 77759, 0, 61, 0], [2, 77760, 0, 46, 80], [2, 77760, 0, 58, 80], [2, 78719, 0, 46, 0], [2, 78719, 0, 58, 0], [2, 78720, 0, 46, 80], [2, 78720, 0, 58, 80], [2, 79679, 0, 46, 0], [2, 79679, 0, 58, 0], [2, 79680, 0, 46, 80], [2, 79680, 0, 58, 80], [2, 80159, 0, 46, 0], [2, 80159, 0, 58, 0], [2, 80160, 0, 46, 80], [2, 80160, 0, 58, 80], [2, 80279, 0, 46, 0], [2, 80279, 0, 58, 0], [2, 80280, 0, 46, 80], [2, 80280, 0, 58, 80], [2, 80399, 0, 46, 0], [2, 80399, 0, 58, 0], [2, 80400, 0, 46, 80], [2, 80400, 0, 58, 80], [2, 80519, 0, 46, 0], [2, 80519, 0, 58, 0], [2, 80640, 0, 59, 80], [2, 80640, 0, 47, 80], [2, 81119, 0, 59, 0], [2, 81119, 0, 47, 0], [2, 81120, 0, 59, 80], [2, 81120, 0, 47, 80], [2, 81359, 0, 59, 0], [2, 81360, 0, 59, 80], [2, 81439, 0, 59, 0], [2, 81440, 0, 59, 80], [2, 81519, 0, 59, 0], [2, 81520, 0, 59, 80], [2, 81599, 0, 47, 0], [2, 81599, 0, 59, 0], [2, 81600, 0, 59, 80], [2, 81600, 0, 47, 80], [2, 81839, 0, 59, 0], [2, 81840, 0, 59, 80], [2, 81959, 0, 59, 0], [2, 81960, 0, 59, 80], [2, 82079, 0, 47, 0], [2, 82079, 0, 59, 0], [2, 82080, 0, 58, 80], [2, 82080, 0, 46, 80], [2, 82199, 0, 58, 0], [2, 82200, 0, 58, 80], [2, 82319, 0, 58, 0], [2, 82320, 0, 58, 80], [2, 82559, 0, 46, 0], [2, 82559, 0, 58, 0], [2, 82560, 0, 59, 80], [2, 82560, 0, 47, 80], [2, 83039, 0, 59, 0], [2, 83039, 0, 47, 0], [2, 83040, 0, 59, 80], [2, 83040, 0, 47, 80], [2, 83279, 0, 59, 0], [2, 83280, 0, 59, 80], [2, 83359, 0, 59, 0], [2, 83360, 0, 59, 80], [2, 83439, 0, 59, 0], [2, 83440, 0, 59, 80], [2, 83519, 0, 47, 0], [2, 83519, 0, 59, 0], [2, 83520, 0, 59, 80], [2, 83520, 0, 47, 80], [2, 83759, 0, 59, 0], [2, 83760, 0, 59, 80], [2, 83879, 0, 59, 0], [2, 83880, 0, 59, 80], [2, 83999, 0, 47, 0], [2, 83999, 0, 59, 0], [2, 84000, 0, 58, 80], [2, 84000, 0, 46, 80], [2, 84119, 0, 58, 0], [2, 84120, 0, 58, 80], [2, 84239, 0, 58, 0], [2, 84240, 0, 58, 80], [2, 84479, 0, 46, 0], [2, 84479, 0, 58, 0], [2, 84480, 0, 60, 80], [2, 84480, 0, 48, 80], [2, 84959, 0, 60, 0], [2, 84959, 0, 48, 0], [2, 84960, 0, 60, 80], [2, 84960, 0, 48, 80], [2, 85199, 0, 60, 0], [2, 85200, 0, 60, 80], [2, 85279, 0, 60, 0], [2, 85280, 0, 60, 80], [2, 85359, 0, 60, 0], [2, 85360, 0, 60, 80], [2, 85439, 0, 48, 0], [2, 85439, 0, 60, 0], [2, 85440, 0, 60, 80], [2, 85440, 0, 48, 80], [2, 85679, 0, 60, 0], [2, 85680, 0, 60, 80], [2, 85799, 0, 60, 0], [2, 85800, 0, 60, 80], [2, 85919, 0, 48, 0], [2, 85919, 0, 60, 0], [2, 85920, 0, 59, 80], [2, 85920, 0, 47, 80], [2, 85920, 0, 56, 80], [2, 86039, 0, 59, 0], [2, 86040, 0, 59, 80], [2, 86159, 0, 59, 0], [2, 86160, 0, 59, 80], [2, 86399, 0, 47, 0], [2, 86399, 0, 56, 0], [2, 86399, 0, 59, 0], [2, 86400, 0, 60, 80], [2, 86400, 0, 48, 80], [2, 86879, 0, 60, 0], [2, 86879, 0, 48, 0], [2, 86880, 0, 60, 80], [2, 86880, 0, 48, 80], [2, 87119, 0, 60, 0], [2, 87120, 0, 60, 80], [2, 87199, 0, 60, 0], [2, 87200, 0, 60, 80], [2, 87279, 0, 60, 0], [2, 87280, 0, 60, 80], [2, 87359, 0, 48, 0], [2, 87359, 0, 60, 0], [2, 87360, 0, 60, 80], [2, 87360, 0, 48, 80], [2, 87599, 0, 60, 0], [2, 87600, 0, 60, 80], [2, 87719, 0, 60, 0], [2, 87720, 0, 60, 80], [2, 87839, 0, 48, 0], [2, 87839, 0, 60, 0], [2, 87840, 0, 59, 80], [2, 87840, 0, 47, 80], [2, 87840, 0, 56, 80], [2, 87959, 0, 59, 0], [2, 87960, 0, 59, 80], [2, 88079, 0, 59, 0], [2, 88080, 0, 59, 80], [2, 88319, 0, 47, 0], [2, 88319, 0, 56, 0], [2, 88319, 0, 59, 0], [2, 88320, 0, 43, 80], [2, 88320, 0, 50, 80], [2, 88320, 0, 55, 80], [2, 88799, 0, 43, 0], [2, 88799, 0, 50, 0], [2, 88799, 0, 55, 0], [2, 88800, 0, 43, 80], [2, 88800, 0, 50, 80], [2, 88800, 0, 55, 80], [2, 89279, 0, 43, 0], [2, 89279, 0, 50, 0], [2, 89279, 0, 55, 0], [2, 89280, 0, 43, 80], [2, 89280, 0, 50, 80], [2, 89280, 0, 55, 80], [2, 89759, 0, 43, 0], [2, 89759, 0, 50, 0], [2, 89759, 0, 55, 0], [2, 89760, 0, 42, 80], [2, 89760, 0, 51, 80], [2, 89760, 0, 54, 80], [2, 90239, 0, 42, 0], [2, 90239, 0, 51, 0], [2, 90239, 0, 54, 0], [2, 90240, 0, 43, 80], [2, 90240, 0, 50, 80], [2, 90240, 0, 55, 80], [2, 90719, 0, 43, 0], [2, 90719, 0, 50, 0], [2, 90719, 0, 55, 0], [2, 90720, 0, 42, 80], [2, 90720, 0, 51, 80], [2, 90720, 0, 54, 80], [2, 91199, 0, 42, 0], [2, 91199, 0, 51, 0], [2, 91199, 0, 54, 0], [2, 91200, 0, 43, 80], [2, 91200, 0, 50, 80], [2, 91200, 0, 55, 80], [2, 91440, 0, 55, 80], [2, 91559, 0, 55, 0], [2, 91560, 0, 55, 80], [2, 91679, 0, 55, 0], [2, 91680, 0, 55, 80], [2, 91799, 0, 55, 0], [2, 91800, 0, 55, 80], [2, 91919, 0, 55, 0], [2, 91920, 0, 55, 80], [2, 92159, 0, 43, 0], [2, 92159, 0, 50, 0], [2, 92159, 0, 55, 0], [2, 92159, 0, 55, 0], [2, 92160, 0, 43, 80], [2, 92160, 0, 50, 80], [2, 92160, 0, 55, 80], [2, 92639, 0, 43, 0], [2, 92639, 0, 50, 0], [2, 92639, 0, 55, 0], [2, 92640, 0, 43, 80], [2, 92640, 0, 50, 80], [2, 92640, 0, 55, 80], [2, 93119, 0, 43, 0], [2, 93119, 0, 50, 0], [2, 93119, 0, 55, 0], [2, 93120, 0, 43, 80], [2, 93120, 0, 50, 80], [2, 93120, 0, 55, 80], [2, 93599, 0, 43, 0], [2, 93599, 0, 50, 0], [2, 93599, 0, 55, 0], [2, 93600, 0, 42, 80], [2, 93600, 0, 51, 80], [2, 93600, 0, 54, 80], [2, 94079, 0, 42, 0], [2, 94079, 0, 51, 0], [2, 94079, 0, 54, 0], [2, 94080, 0, 39, 80], [2, 94080, 0, 46, 80], [2, 94080, 0, 51, 80], [2, 94559, 0, 39, 0], [2, 94559, 0, 46, 0], [2, 94559, 0, 51, 0], [2, 94560, 0, 36, 80], [2, 94560, 0, 43, 80], [2, 94560, 0, 48, 80], [2, 95039, 0, 36, 0], [2, 95039, 0, 43, 0], [2, 95039, 0, 48, 0], [2, 95040, 0, 43, 80], [2, 95040, 0, 50, 80], [2, 95040, 0, 55, 80], [2, 95280, 0, 55, 80], [2, 95399, 0, 55, 0], [2, 95400, 0, 55, 80], [2, 95519, 0, 55, 0], [2, 95520, 0, 55, 80], [2, 95639, 0, 55, 0], [2, 95640, 0, 55, 80], [2, 95759, 0, 55, 0], [2, 95760, 0, 55, 80], [2, 95999, 0, 43, 0], [2, 95999, 0, 50, 0], [2, 95999, 0, 55, 0], [2, 95999, 0, 55, 0], [2, 96000, 0, 43, 80], [2, 96000, 0, 50, 80], [2, 96000, 0, 55, 80], [2, 96479, 0, 43, 0], [2, 96479, 0, 50, 0], [2, 96479, 0, 55, 0], [2, 96480, 0, 43, 80], [2, 96480, 0, 50, 80], [2, 96480, 0, 55, 80], [2, 96959, 0, 43, 0], [2, 96959, 0, 50, 0], [2, 96959, 0, 55, 0], [2, 96960, 0, 43, 80], [2, 96960, 0, 50, 80], [2, 96960, 0, 55, 80], [2, 97439, 0, 43, 0], [2, 97439, 0, 50, 0], [2, 97439, 0, 55, 0], [2, 97440, 0, 43, 80], [2, 97440, 0, 50, 80], [2, 97440, 0, 55, 80], [2, 97919, 0, 43, 0], [2, 97919, 0, 50, 0], [2, 97919, 0, 55, 0], [2, 97920, 0, 37, 80], [2, 97920, 0, 44, 80], [2, 97920, 0, 49, 80], [2, 98399, 0, 37, 0], [2, 98399, 0, 44, 0], [2, 98399, 0, 49, 0], [2, 98400, 0, 37, 80], [2, 98400, 0, 44, 80], [2, 98400, 0, 49, 80], [2, 98879, 0, 37, 0], [2, 98879, 0, 44, 0], [2, 98879, 0, 49, 0], [2, 98880, 0, 37, 80], [2, 98880, 0, 44, 80], [2, 98880, 0, 49, 80], [2, 99359, 0, 37, 0], [2, 99359, 0, 44, 0], [2, 99359, 0, 49, 0], [2, 99360, 0, 37, 80], [2, 99360, 0, 44, 80], [2, 99360, 0, 49, 80], [2, 99839, 0, 37, 0], [2, 99839, 0, 44, 0], [2, 99839, 0, 49, 0], [2, 99840, 0, 39, 80], [2, 99840, 0, 46, 80], [2, 99840, 0, 51, 80], [2, 100319, 0, 39, 0], [2, 100319, 0, 46, 0], [2, 100319, 0, 51, 0], [2, 100320, 0, 39, 80], [2, 100320, 0, 46, 80], [2, 100320, 0, 51, 80], [2, 100799, 0, 39, 0], [2, 100799, 0, 46, 0], [2, 100799, 0, 51, 0], [2, 100800, 0, 36, 80], [2, 100800, 0, 43, 80], [2, 100800, 0, 48, 80], [2, 101279, 0, 36, 0], [2, 101279, 0, 43, 0], [2, 101279, 0, 48, 0], [2, 101280, 0, 39, 80], [2, 101280, 0, 46, 80], [2, 101280, 0, 51, 80], [2, 101759, 0, 39, 0], [2, 101759, 0, 46, 0], [2, 101759, 0, 51, 0], [2, 101760, 0, 43, 80], [2, 101760, 0, 50, 80], [2, 101760, 0, 55, 80], [2, 102239, 0, 43, 0], [2, 102239, 0, 50, 0], [2, 102239, 0, 55, 0], [2, 102240, 0, 39, 80], [2, 102240, 0, 46, 80], [2, 102240, 0, 51, 80], [2, 102719, 0, 39, 0], [2, 102719, 0, 46, 0], [2, 102719, 0, 51, 0], [2, 102720, 0, 43, 80], [2, 102720, 0, 50, 80], [2, 102720, 0, 55, 80], [2, 103199, 0, 43, 0], [2, 103199, 0, 50, 0], [2, 103199, 0, 55, 0], [2, 103200, 0, 43, 80], [2, 103200, 0, 50, 80], [2, 103200, 0, 55, 80], [2, 103679, 0, 43, 0], [2, 103679, 0, 50, 0], [2, 103679, 0, 55, 0], [2, 103680, 0, 39, 80], [2, 103680, 0, 46, 80], [2, 103680, 0, 51, 80], [2, 104159, 0, 39, 0], [2, 104159, 0, 46, 0], [2, 104159, 0, 51, 0], [2, 104160, 0, 39, 80], [2, 104160, 0, 46, 80], [2, 104160, 0, 51, 80], [2, 104639, 0, 39, 0], [2, 104639, 0, 46, 0], [2, 104639, 0, 51, 0], [2, 104640, 0, 43, 80], [2, 104640, 0, 50, 80], [2, 104640, 0, 55, 80], [2, 105119, 0, 43, 0], [2, 105119, 0, 50, 0], [2, 105119, 0, 55, 0], [2, 105120, 0, 43, 80], [2, 105120, 0, 50, 80], [2, 105120, 0, 55, 80], [2, 105599, 0, 43, 0], [2, 105599, 0, 50, 0], [2, 105599, 0, 55, 0], [2, 105600, 0, 37, 80], [2, 105600, 0, 44, 80], [2, 105600, 0, 49, 80], [2, 106079, 0, 37, 0], [2, 106079, 0, 44, 0], [2, 106079, 0, 49, 0], [2, 106080, 0, 37, 80], [2, 106080, 0, 44, 80], [2, 106080, 0, 49, 80], [2, 106559, 0, 37, 0], [2, 106559, 0, 44, 0], [2, 106559, 0, 49, 0], [2, 106560, 0, 37, 80], [2, 106560, 0, 44, 80], [2, 106560, 0, 49, 80], [2, 107039, 0, 37, 0], [2, 107039, 0, 44, 0], [2, 107039, 0, 49, 0], [2, 107040, 0, 37, 80], [2, 107040, 0, 44, 80], [2, 107040, 0, 49, 80], [2, 107519, 0, 37, 0], [2, 107519, 0, 44, 0], [2, 107519, 0, 49, 0], [2, 107520, 0, 39, 80], [2, 107520, 0, 46, 80], [2, 107520, 0, 51, 80], [2, 107999, 0, 39, 0], [2, 107999, 0, 46, 0], [2, 107999, 0, 51, 0], [2, 108000, 0, 39, 80], [2, 108000, 0, 46, 80], [2, 108000, 0, 51, 80], [2, 108479, 0, 39, 0], [2, 108479, 0, 46, 0], [2, 108479, 0, 51, 0], [2, 108480, 0, 39, 80], [2, 108480, 0, 46, 80], [2, 108480, 0, 51, 80], [2, 108959, 0, 39, 0], [2, 108959, 0, 46, 0], [2, 108959, 0, 51, 0], [2, 108960, 0, 36, 80], [2, 108960, 0, 43, 80], [2, 108960, 0, 48, 80], [2, 109439, 0, 36, 0], [2, 109439, 0, 43, 0], [2, 109439, 0, 48, 0], [2, 109440, 0, 43, 80], [2, 109440, 0, 50, 80], [2, 109440, 0, 55, 80], [2, 109919, 0, 43, 0], [2, 109919, 0, 50, 0], [2, 109919, 0, 55, 0], [2, 109920, 0, 42, 80], [2, 109920, 0, 46, 80], [2, 109920, 0, 51, 80], [2, 109920, 0, 54, 80], [2, 110399, 0, 42, 0], [2, 110399, 0, 46, 0], [2, 110399, 0, 51, 0], [2, 110399, 0, 54, 0], [2, 110400, 0, 43, 80], [2, 110400, 0, 50, 80], [2, 110400, 0, 55, 80], [2, 110879, 0, 43, 0], [2, 110879, 0, 50, 0], [2, 110879, 0, 55, 0], [2, 110880, 0, 43, 80], [2, 110880, 0, 50, 80], [2, 110880, 0, 55, 80], [2, 111359, 0, 43, 0], [2, 111359, 0, 50, 0], [2, 111359, 0, 55, 0], [2, 111840, 0, 43, 80], [2, 111840, 0, 50, 80], [2, 111840, 0, 55, 80], [2, 111959, 0, 43, 0], [2, 111959, 0, 50, 0], [2, 111959, 0, 55, 0], [2, 111960, 0, 43, 80], [2, 111960, 0, 50, 80], [2, 111960, 0, 55, 80], [2, 112079, 0, 43, 0], [2, 112079, 0, 50, 0], [2, 112079, 0, 55, 0], [2, 112080, 0, 43, 80], [2, 112080, 0, 50, 80], [2, 112080, 0, 55, 80], [2, 112199, 0, 43, 0], [2, 112199, 0, 50, 0], [2, 112199, 0, 55, 0], [2, 112560, 0, 43, 80], [2, 112560, 0, 50, 80], [2, 112560, 0, 55, 80], [2, 112799, 0, 43, 0], [2, 112799, 0, 50, 0], [2, 112799, 0, 55, 0], [2, 113040, 0, 42, 80], [2, 113040, 0, 46, 80], [2, 113040, 0, 51, 80], [2, 113040, 0, 54, 80], [2, 113279, 0, 42, 0], [2, 113279, 0, 46, 0], [2, 113279, 0, 51, 0], [2, 113279, 0, 54, 0], [2, 113520, 0, 43, 80], [2, 113520, 0, 50, 80], [2, 113520, 0, 55, 80], [2, 113759, 0, 43, 0], [2, 113759, 0, 50, 0], [2, 113759, 0, 55, 0], [2, 114000, 0, 42, 80], [2, 114000, 0, 46, 80], [2, 114000, 0, 51, 80], [2, 114000, 0, 54, 80], [2, 114239, 0, 42, 0], [2, 114239, 0, 46, 0], [2, 114239, 0, 51, 0], [2, 114239, 0, 54, 0], [2, 114480, 0, 43, 80], [2, 114480, 0, 50, 80], [2, 114480, 0, 55, 80], [2, 114599, 0, 43, 0], [2, 114599, 0, 50, 0], [2, 114599, 0, 55, 0], [2, 114600, 0, 43, 80], [2, 114600, 0, 50, 80], [2, 114600, 0, 55, 80], [2, 114719, 0, 43, 0], [2, 114719, 0, 50, 0], [2, 114719, 0, 55, 0], [2, 114720, 0, 43, 80], [2, 114720, 0, 50, 80], [2, 114720, 0, 55, 80], [2, 114839, 0, 43, 0], [2, 114839, 0, 50, 0], [2, 114839, 0, 55, 0], [2, 114840, 0, 43, 80], [2, 114840, 0, 50, 80], [2, 114840, 0, 55, 80], [2, 114959, 0, 43, 0], [2, 114959, 0, 50, 0], [2, 114959, 0, 55, 0], [2, 114960, 0, 43, 80], [2, 114960, 0, 50, 80], [2, 114960, 0, 55, 80], [2, 115079, 0, 43, 0], [2, 115079, 0, 50, 0], [2, 115079, 0, 55, 0], [2, 115440, 0, 43, 96], [2, 115440, 0, 50, 96], [2, 115440, 0, 55, 96], [2, 115679, 0, 43, 0], [2, 115679, 0, 50, 0], [2, 115679, 0, 55, 0], [2, 115920, 0, 43, 96], [2, 115920, 0, 50, 96], [2, 115920, 0, 55, 96], [2, 116039, 0, 43, 0], [2, 116039, 0, 50, 0], [2, 116039, 0, 55, 0], [2, 116040, 0, 43, 96], [2, 116040, 0, 50, 96], [2, 116040, 0, 55, 96], [2, 116159, 0, 43, 0], [2, 116159, 0, 50, 0], [2, 116159, 0, 55, 0], [2, 116400, 0, 43, 96], [2, 116400, 0, 50, 96], [2, 116400, 0, 55, 96], [2, 116639, 0, 43, 0], [2, 116639, 0, 50, 0], [2, 116639, 0, 55, 0], [2, 116880, 0, 39, 96], [2, 116880, 0, 51, 96], [2, 117119, 0, 39, 0], [2, 117119, 0, 51, 0], [2, 117360, 0, 36, 96], [2, 117360, 0, 48, 96], [2, 117599, 0, 36, 0], [2, 117599, 0, 48, 0], [2, 117840, 0, 39, 96], [2, 117840, 0, 51, 96], [2, 118079, 0, 39, 0], [2, 118079, 0, 51, 0], [2, 118320, 0, 43, 96], [2, 118320, 0, 50, 96], [2, 118320, 0, 55, 96], [2, 118439, 0, 43, 0], [2, 118439, 0, 50, 0], [2, 118439, 0, 55, 0], [2, 118440, 0, 43, 96], [2, 118440, 0, 50, 96], [2, 118440, 0, 55, 96], [2, 118559, 0, 43, 0], [2, 118559, 0, 50, 0], [2, 118559, 0, 55, 0], [2, 118560, 0, 43, 96], [2, 118560, 0, 50, 96], [2, 118560, 0, 55, 96], [2, 118679, 0, 43, 0], [2, 118679, 0, 50, 0], [2, 118679, 0, 55, 0], [2, 118680, 0, 43, 96], [2, 118680, 0, 50, 96], [2, 118680, 0, 55, 96], [2, 118799, 0, 43, 0], [2, 118799, 0, 50, 0], [2, 118799, 0, 55, 0], [2, 118800, 0, 43, 96], [2, 118800, 0, 50, 96], [2, 118800, 0, 55, 96], [2, 118919, 0, 43, 0], [2, 118919, 0, 50, 0], [2, 118919, 0, 55, 0], [2, 119040, 0, 43, 96], [2, 119040, 0, 51, 96], [2, 119040, 0, 55, 96], [2, 119519, 0, 43, 0], [2, 119519, 0, 51, 0], [2, 119519, 0, 55, 0], [2, 119520, 0, 43, 96], [2, 119520, 0, 51, 96], [2, 119520, 0, 55, 96], [2, 119999, 0, 43, 0], [2, 119999, 0, 51, 0], [2, 119999, 0, 55, 0], [2, 120000, 0, 43, 96], [2, 120000, 0, 50, 96], [2, 120000, 0, 55, 96], [2, 120479, 0, 43, 0], [2, 120479, 0, 50, 0], [2, 120479, 0, 55, 0], [2, 120480, 0, 43, 96], [2, 120480, 0, 50, 96], [2, 120480, 0, 55, 96], [2, 120959, 0, 43, 0], [2, 120959, 0, 50, 0], [2, 120959, 0, 55, 0], [2, 120960, 0, 37, 96], [2, 120960, 0, 44, 96], [2, 120960, 0, 49, 96], [2, 121439, 0, 37, 0], [2, 121439, 0, 44, 0], [2, 121439, 0, 49, 0], [2, 121440, 0, 37, 96], [2, 121440, 0, 44, 96], [2, 121440, 0, 49, 96], [2, 121919, 0, 37, 0], [2, 121919, 0, 44, 0], [2, 121919, 0, 49, 0], [2, 121920, 0, 37, 96], [2, 121920, 0, 44, 96], [2, 121920, 0, 49, 96], [2, 122399, 0, 37, 0], [2, 122399, 0, 44, 0], [2, 122399, 0, 49, 0], [2, 122400, 0, 37, 96], [2, 122400, 0, 44, 96], [2, 122400, 0, 49, 96], [2, 122879, 0, 37, 0], [2, 122879, 0, 44, 0], [2, 122879, 0, 49, 0], [2, 122880, 0, 39, 96], [2, 122880, 0, 46, 96], [2, 122880, 0, 51, 96], [2, 123359, 0, 39, 0], [2, 123359, 0, 46, 0], [2, 123359, 0, 51, 0], [2, 123360, 0, 39, 96], [2, 123360, 0, 46, 96], [2, 123360, 0, 51, 96], [2, 123839, 0, 39, 0], [2, 123839, 0, 46, 0], [2, 123839, 0, 51, 0], [2, 123840, 0, 39, 96], [2, 123840, 0, 46, 96], [2, 123840, 0, 51, 96], [2, 124319, 0, 39, 0], [2, 124319, 0, 46, 0], [2, 124319, 0, 51, 0], [2, 124320, 0, 36, 96], [2, 124320, 0, 43, 96], [2, 124320, 0, 48, 96], [2, 124799, 0, 36, 0], [2, 124799, 0, 43, 0], [2, 124799, 0, 48, 0], [2, 124800, 0, 43, 96], [2, 124800, 0, 50, 96], [2, 124800, 0, 55, 96], [2, 125279, 0, 43, 0], [2, 125279, 0, 50, 0], [2, 125279, 0, 55, 0], [2, 125280, 0, 42, 96], [2, 125280, 0, 46, 96], [2, 125280, 0, 51, 96], [2, 125280, 0, 54, 96], [2, 125759, 0, 42, 0], [2, 125759, 0, 46, 0], [2, 125759, 0, 51, 0], [2, 125759, 0, 54, 0], [2, 125760, 0, 43, 96], [2, 125760, 0, 50, 96], [2, 125760, 0, 55, 96], [2, 125999, 0, 43, 0], [2, 125999, 0, 50, 0], [2, 125999, 0, 55, 0], [2, 126000, 0, 43, 96], [2, 126000, 0, 50, 96], [2, 126000, 0, 55, 96], [2, 126119, 0, 43, 0], [2, 126119, 0, 50, 0], [2, 126119, 0, 55, 0], [2, 126120, 0, 43, 96], [2, 126120, 0, 50, 96], [2, 126120, 0, 55, 96], [2, 126239, 0, 43, 0], [2, 126239, 0, 50, 0], [2, 126239, 0, 55, 0], [2, 126240, 0, 43, 96], [2, 126240, 0, 50, 96], [2, 126240, 0, 55, 96], [2, 126359, 0, 43, 0], [2, 126359, 0, 50, 0], [2, 126359, 0, 55, 0], [2, 126360, 0, 43, 96], [2, 126360, 0, 50, 96], [2, 126360, 0, 55, 96], [2, 126479, 0, 43, 0], [2, 126479, 0, 50, 0], [2, 126479, 0, 55, 0], [2, 126480, 0, 43, 96], [2, 126480, 0, 50, 96], [2, 126480, 0, 55, 96], [2, 126599, 0, 43, 0], [2, 126599, 0, 50, 0], [2, 126599, 0, 55, 0], [2, 126720, 0, 55, 96], [2, 126720, 0, 43, 96], [2, 127199, 0, 55, 0], [2, 127199, 0, 43, 0], [2, 127200, 0, 55, 96], [2, 127200, 0, 43, 96], [2, 127439, 0, 55, 0], [2, 127440, 0, 55, 96], [2, 127519, 0, 55, 0], [2, 127520, 0, 55, 96], [2, 127599, 0, 55, 0], [2, 127600, 0, 55, 96], [2, 127679, 0, 43, 0], [2, 127679, 0, 55, 0], [2, 127680, 0, 55, 96], [2, 127680, 0, 43, 96], [2, 127919, 0, 55, 0], [2, 127920, 0, 55, 96], [2, 128039, 0, 55, 0], [2, 128040, 0, 55, 96], [2, 128159, 0, 43, 0], [2, 128159, 0, 55, 0], [2, 128160, 0, 51, 96], [2, 128160, 0, 54, 96], [2, 128160, 0, 39, 96], [2, 128279, 0, 51, 0], [2, 128279, 0, 54, 0], [2, 128280, 0, 54, 96], [2, 128399, 0, 54, 0], [2, 128400, 0, 54, 96], [2, 128639, 0, 39, 0], [2, 128639, 0, 54, 0], [2, 128640, 0, 55, 96], [2, 128640, 0, 43, 96], [2, 129119, 0, 55, 0], [2, 129119, 0, 43, 0], [2, 129120, 0, 55, 96], [2, 129120, 0, 43, 96], [2, 129359, 0, 55, 0], [2, 129360, 0, 55, 96], [2, 129439, 0, 55, 0], [2, 129440, 0, 55, 96], [2, 129519, 0, 55, 0], [2, 129520, 0, 55, 96], [2, 129599, 0, 43, 0], [2, 129599, 0, 55, 0], [2, 129600, 0, 55, 96], [2, 129600, 0, 43, 96], [2, 129839, 0, 55, 0], [2, 129840, 0, 55, 96], [2, 129959, 0, 55, 0], [2, 129960, 0, 55, 96], [2, 130079, 0, 43, 0], [2, 130079, 0, 55, 0], [2, 130080, 0, 51, 96], [2, 130080, 0, 54, 96], [2, 130080, 0, 39, 96], [2, 130199, 0, 51, 0], [2, 130199, 0, 54, 0], [2, 130200, 0, 54, 96], [2, 130319, 0, 54, 0], [2, 130320, 0, 54, 96], [2, 130559, 0, 39, 0], [2, 130559, 0, 54, 0], [2, 130560, 0, 55, 96], [2, 130560, 0, 43, 96], [2, 131039, 0, 55, 0], [2, 131039, 0, 43, 0], [2, 131040, 0, 55, 96], [2, 131040, 0, 43, 96], [2, 131279, 0, 55, 0], [2, 131280, 0, 55, 96], [2, 131359, 0, 55, 0], [2, 131360, 0, 55, 96], [2, 131439, 0, 55, 0], [2, 131440, 0, 55, 96], [2, 131519, 0, 43, 0], [2, 131519, 0, 55, 0], [2, 131520, 0, 55, 96], [2, 131520, 0, 43, 96], [2, 131759, 0, 55, 0], [2, 131760, 0, 55, 96], [2, 131879, 0, 55, 0], [2, 131880, 0, 55, 96], [2, 131999, 0, 43, 0], [2, 131999, 0, 55, 0], [2, 132000, 0, 54, 96], [2, 132000, 0, 58, 96], [2, 132000, 0, 39, 96], [2, 132119, 0, 54, 0], [2, 132119, 0, 58, 0], [2, 132120, 0, 54, 96], [2, 132239, 0, 54, 0], [2, 132240, 0, 54, 96], [2, 132479, 0, 39, 0], [2, 132479, 0, 54, 0], [2, 132480, 0, 55, 96], [2, 132480, 0, 43, 96], [2, 132959, 0, 55, 0], [2, 132959, 0, 43, 0], [2, 132960, 0, 55, 96], [2, 132960, 0, 43, 96], [2, 133199, 0, 55, 0], [2, 133200, 0, 55, 96], [2, 133279, 0, 55, 0], [2, 133280, 0, 55, 96], [2, 133359, 0, 55, 0], [2, 133360, 0, 55, 96], [2, 133439, 0, 43, 0], [2, 133439, 0, 55, 0], [2, 133440, 0, 55, 96], [2, 133440, 0, 43, 96], [2, 133679, 0, 55, 0], [2, 133680, 0, 55, 96], [2, 133799, 0, 55, 0], [2, 133800, 0, 55, 96], [2, 133919, 0, 43, 0], [2, 133919, 0, 55, 0], [2, 133920, 0, 54, 96], [2, 133920, 0, 58, 96], [2, 133920, 0, 39, 96], [2, 134039, 0, 54, 0], [2, 134039, 0, 58, 0], [2, 134040, 0, 54, 96], [2, 134159, 0, 54, 0], [2, 134160, 0, 54, 96], [2, 134399, 0, 39, 0], [2, 134399, 0, 54, 0], [2, 134400, 0, 55, 96], [2, 134879, 0, 55, 0], [2, 134880, 0, 54, 96], [2, 135359, 0, 54, 0], [2, 135360, 0, 52, 96], [2, 135839, 0, 52, 0], [2, 135840, 0, 50, 96], [2, 136319, 0, 50, 0], [2, 136320, 0, 48, 96], [2, 136799, 0, 48, 0], [2, 136800, 0, 46, 96], [2, 137279, 0, 46, 0], [2, 137280, 0, 45, 96], [2, 137759, 0, 45, 0], [2, 137760, 0, 44, 96], [2, 138239, 0, 44, 0], [2, 138240, 0, 43, 96], [2, 138719, 0, 43, 0], [2, 138720, 0, 45, 96], [2, 138959, 0, 45, 0], [2, 138960, 0, 46, 96], [2, 139039, 0, 46, 0], [2, 139040, 0, 46, 96], [2, 139119, 0, 46, 0], [2, 139120, 0, 46, 96], [2, 139199, 0, 46, 0], [2, 139200, 0, 48, 96], [2, 139439, 0, 48, 0], [2, 139440, 0, 50, 96], [2, 139559, 0, 50, 0], [2, 139560, 0, 50, 96], [2, 139679, 0, 50, 0], [2, 139680, 0, 51, 96], [2, 139799, 0, 51, 0], [2, 139800, 0, 51, 96], [2, 139919, 0, 51, 0], [2, 139920, 0, 52, 96], [2, 140159, 0, 52, 0], [2, 140160, 0, 53, 96], [2, 140639, 0, 53, 0], [2, 140640, 0, 54, 96], [2, 140879, 0, 54, 0], [2, 140880, 0, 54, 96], [2, 140959, 0, 54, 0], [2, 140960, 0, 54, 96], [2, 141039, 0, 54, 0], [2, 141040, 0, 54, 96], [2, 141119, 0, 54, 0], [2, 141120, 0, 55, 96], [2, 141359, 0, 55, 0], [2, 141360, 0, 55, 96], [2, 141479, 0, 55, 0], [2, 141480, 0, 55, 96], [2, 141599, 0, 55, 0], [2, 141600, 0, 57, 96], [2, 141719, 0, 57, 0], [2, 141720, 0, 57, 96], [2, 141839, 0, 57, 0], [2, 141840, 0, 57, 96], [2, 142079, 0, 57, 0], [2, 142080, 0, 58, 96], [2, 142080, 0, 38, 96], [2, 142159, 0, 58, 0], [2, 142160, 0, 58, 96], [2, 142239, 0, 58, 0], [2, 142240, 0, 58, 96], [2, 142319, 0, 38, 0], [2, 142319, 0, 58, 0], [2, 142320, 0, 48, 80], [2, 142320, 0, 59, 80], [2, 142320, 0, 39, 80], [2, 142399, 0, 48, 0], [2, 142399, 0, 59, 0], [2, 142400, 0, 46, 80], [2, 142479, 0, 46, 0], [2, 142480, 0, 48, 81], [2, 142559, 0, 48, 0], [2, 142560, 0, 50, 82], [2, 142639, 0, 50, 0], [2, 142640, 0, 48, 83], [2, 142719, 0, 48, 0], [2, 142720, 0, 50, 84], [2, 142799, 0, 50, 0], [2, 142800, 0, 51, 85], [2, 142879, 0, 51, 0], [2, 142880, 0, 50, 86], [2, 142959, 0, 50, 0], [2, 142960, 0, 51, 87], [2, 143039, 0, 51, 0], [2, 143040, 0, 53, 88], [2, 143119, 0, 53, 0], [2, 143120, 0, 51, 89], [2, 143199, 0, 51, 0], [2, 143200, 0, 53, 90], [2, 143279, 0, 53, 0], [2, 143280, 0, 54, 91], [2, 143359, 0, 54, 0], [2, 143360, 0, 53, 92], [2, 143439, 0, 53, 0], [2, 143440, 0, 54, 93], [2, 143519, 0, 54, 0], [2, 143520, 0, 55, 94], [2, 143599, 0, 55, 0], [2, 143600, 0, 54, 95], [2, 143679, 0, 54, 0], [2, 143680, 0, 55, 96], [2, 143759, 0, 55, 0], [2, 143760, 0, 57, 97], [2, 143839, 0, 57, 0], [2, 143840, 0, 55, 98], [2, 143919, 0, 55, 0], [2, 143920, 0, 57, 99], [2, 143999, 0, 57, 0], [2, 144000, 0, 58, 100], [2, 144079, 0, 58, 0], [2, 144080, 0, 55, 101], [2, 144159, 0, 55, 0], [2, 144160, 0, 57, 103], [2, 144239, 0, 57, 0], [2, 144240, 0, 58, 104], [2, 144319, 0, 58, 0], [2, 144320, 0, 60, 105], [2, 144399, 0, 60, 0], [2, 144400, 0, 62, 106], [2, 144479, 0, 62, 0], [2, 145919, 0, 39, 0], [2, 145920, 0, 43, 126], [2, 145920, 0, 50, 126], [2, 145920, 0, 55, 126], [2, 146399, 0, 43, 0], [2, 146399, 0, 50, 0], [2, 146399, 0, 55, 0], [2, 146400, 0, 43, 126], [2, 146400, 0, 50, 126], [2, 146400, 0, 55, 126], [2, 146639, 0, 43, 0], [2, 146639, 0, 50, 0], [2, 146639, 0, 55, 0], [2, 146640, 0, 43, 126], [2, 146640, 0, 50, 126], [2, 146640, 0, 55, 126], [2, 146719, 0, 43, 0], [2, 146719, 0, 50, 0], [2, 146719, 0, 55, 0], [2, 146720, 0, 43, 126], [2, 146720, 0, 50, 126], [2, 146720, 0, 55, 126], [2, 146799, 0, 43, 0], [2, 146799, 0, 50, 0], [2, 146799, 0, 55, 0], [2, 146800, 0, 43, 126], [2, 146800, 0, 50, 126], [2, 146800, 0, 55, 126], [2, 146879, 0, 43, 0], [2, 146879, 0, 50, 0], [2, 146879, 0, 55, 0], [2, 146880, 0, 39, 126], [2, 146880, 0, 46, 126], [2, 146880, 0, 51, 126], [2, 146999, 0, 39, 0], [2, 146999, 0, 46, 0], [2, 146999, 0, 51, 0], [2, 147000, 0, 39, 126], [2, 147000, 0, 46, 126], [2, 147000, 0, 51, 126], [2, 147119, 0, 39, 0], [2, 147119, 0, 46, 0], [2, 147119, 0, 51, 0], [2, 147360, 0, 31, 126], [2, 147360, 0, 38, 126], [2, 147360, 0, 43, 126], [2, 147599, 0, 31, 0], [2, 147599, 0, 38, 0], [2, 147599, 0, 43, 0], [2, 147840, 0, 39, 126], [2, 147840, 0, 46, 126], [2, 147840, 0, 51, 126], [2, 148319, 0, 39, 0], [2, 148319, 0, 46, 0], [2, 148319, 0, 51, 0], [2, 148320, 0, 31, 126], [2, 148320, 0, 38, 126], [2, 148320, 0, 43, 126], [2, 148559, 0, 31, 0], [2, 148559, 0, 38, 0], [2, 148559, 0, 43, 0], [2, 148560, 0, 39, 126], [2, 148560, 0, 51, 126], [2, 148799, 0, 39, 0], [2, 148799, 0, 51, 0], [2, 148800, 0, 38, 126], [2, 148800, 0, 50, 126], [2, 149039, 0, 38, 0], [2, 149039, 0, 50, 0], [2, 149040, 0, 31, 126], [2, 149040, 0, 38, 126], [2, 149040, 0, 43, 126], [2, 149279, 0, 31, 0], [2, 149279, 0, 38, 0], [2, 149279, 0, 43, 0]]\n"
     ]
    }
   ],
   "source": [
    "instrument1 = []\n",
    "instrument2 = []\n",
    "for line in lines:\n",
    "    x = line.replace(\" \",\"\")\n",
    "    x = x.split(\",\")\n",
    "    x[len(x)-1] = x[len(x)-1].replace(\"\\n\",\"\");\n",
    "    if len(x) == 6:\n",
    "        x[0] = int(x[0])\n",
    "        x[1] = int(x[1])\n",
    "        x[3] = int(x[3])\n",
    "        x[4] = int(x[4])\n",
    "        x[5] = int(x[5])\n",
    "        if x[1] != 0 and x[1] != '0':\n",
    "            x.remove('Note_on_c')\n",
    "            if x[0] == 1:\n",
    "                instrument1.append(x)\n",
    "#                if x[3] < min1:\n",
    " #                   min1 = x[3]\n",
    "            elif x[0] == 2:\n",
    "                instrument2.append(x)\n",
    "#                if x[3] < min2:\n",
    "#                    min2 = x[3]\n",
    "#            print(x)\n",
    "#print(instrument1)\n",
    "print(instrument2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*36\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*36\n",
      "479-\n",
      "1-+27\n",
      "240-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "239-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*36\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-+27\n",
      "240-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "239-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*.36\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-+2\n",
      "479-\n",
      "1-+2\n",
      "479-\n",
      "1-+2\n",
      "479-\n",
      "1-'.\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+29\n",
      "479-\n",
      "1-+2:\n",
      "479-\n",
      "1-+26\n",
      "479-\n",
      "1-7\n",
      "239-\n",
      "721-7\n",
      "239-\n",
      "721-7\n",
      "239-\n",
      "721-7\n",
      "239-\n",
      "241-7\n",
      "239-\n",
      "241-7\n",
      "239-\n",
      "721-7\n",
      "239-\n",
      "721-7\n",
      "239-\n",
      "721-7\n",
      "239-\n",
      "721-+\n",
      "239-\n",
      "1-2\n",
      "239-\n",
      "1-3\n",
      "239-\n",
      "1-0\n",
      "239-\n",
      "1-+\n",
      "239-\n",
      "721-+\n",
      "239-\n",
      "721-+\n",
      "239-\n",
      "241-+\n",
      "239-\n",
      "241-,\n",
      "239-\n",
      "721-,\n",
      "239-\n",
      "721-,\n",
      "239-\n",
      "721-!-\n",
      "239-\n",
      "721--9\n",
      "479-\n",
      "1--9\n",
      "479-\n",
      "1--9\n",
      "479-\n",
      "1-)5\n",
      "359-\n",
      "1-0<\n",
      "119-\n",
      "1--9\n",
      "479-\n",
      "1-)5\n",
      "359-\n",
      "1-0<\n",
      "119-\n",
      "1--9\n",
      "3839-\n",
      "1-4@\n",
      "479-\n",
      "1-4@\n",
      "479-\n",
      "1-@0\n",
      "479-\n",
      "1-A,\n",
      "359-,\n",
      "1-,<\n",
      "119-\n",
      "1-8)\n",
      "479-\n",
      "1-5&\n",
      "359-&\n",
      "1-&<\n",
      "119-\n",
      "1--9\n",
      "3839-\n",
      "1-:F\n",
      "479-\n",
      "1-.:\n",
      "359-\n",
      "1-.:\n",
      "119-\n",
      "1-:F\n",
      "479-\n",
      "1-9E\n",
      "359-\n",
      "1-8D\n",
      "119-\n",
      "1-7C\n",
      "119-\n",
      "1-6B\n",
      "119-\n",
      "1-7C\n",
      "119-\n",
      "361-/;\n",
      "239-\n",
      "1-4@\n",
      "1679-\n",
      "721-3?\n",
      "359-\n",
      "1-2>\n",
      "119-\n",
      "1-1=\n",
      "119-\n",
      "1-0<\n",
      "119-\n",
      "1-1=\n",
      "119-\n",
      "361-*6\n",
      "239-\n",
      "1--9\n",
      "1919-\n",
      "1-*6\n",
      "479-\n",
      "1-1=\n",
      "479-\n",
      "1-.:\n",
      "479-\n",
      "1-*6\n",
      "359-\n",
      "1-1=\n",
      "119-\n",
      "1-.:\n",
      "959-\n",
      "1-.:\n",
      "959-\n",
      "1-.:\n",
      "479-\n",
      "1-.:\n",
      "119-\n",
      "1-.:\n",
      "119-\n",
      "1-.:\n",
      "119-\n",
      "121-;/\n",
      "479-\n",
      "1-;/\n",
      "239-/\n",
      "1-/;\n",
      "79-/\n",
      "1-/;\n",
      "79-/\n",
      "1-/;\n",
      "79-\n",
      "1-;/\n",
      "239-/\n",
      "1-/;\n",
      "119-/\n",
      "1-/;\n",
      "119-\n",
      "1-:.\n",
      "119-.\n",
      "1-.:\n",
      "119-.\n",
      "1-.:\n",
      "239-\n",
      "1-;/\n",
      "479-\n",
      "1-;/\n",
      "239-/\n",
      "1-/;\n",
      "79-/\n",
      "1-/;\n",
      "79-/\n",
      "1-/;\n",
      "79-\n",
      "1-;/\n",
      "239-/\n",
      "1-/;\n",
      "119-/\n",
      "1-/;\n",
      "119-\n",
      "1-:.\n",
      "119-.\n",
      "1-.:\n",
      "119-.\n",
      "1-.:\n",
      "239-\n",
      "1-<0\n",
      "479-\n",
      "1-<0\n",
      "239-0\n",
      "1-0<\n",
      "79-0\n",
      "1-0<\n",
      "79-0\n",
      "1-0<\n",
      "79-\n",
      "1-<0\n",
      "239-0\n",
      "1-0<\n",
      "119-0\n",
      "1-0<\n",
      "119-\n",
      "1-;/8\n",
      "119-/8\n",
      "1-/8;\n",
      "119-/8\n",
      "1-/8;\n",
      "239-\n",
      "1-<0\n",
      "479-\n",
      "1-<0\n",
      "239-0\n",
      "1-0<\n",
      "79-0\n",
      "1-0<\n",
      "79-0\n",
      "1-0<\n",
      "79-\n",
      "1-<0\n",
      "239-0\n",
      "1-0<\n",
      "119-0\n",
      "1-0<\n",
      "119-\n",
      "1-;/8\n",
      "119-/8\n",
      "1-/8;\n",
      "119-/8\n",
      "1-/8;\n",
      "239-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*36\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*36\n",
      "479-\n",
      "1-+27\n",
      "240-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "239-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*36\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-+27\n",
      "240-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "119-+2\n",
      "1-+27\n",
      "239-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*.36\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "481-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "361-+27\n",
      "239-\n",
      "241-*.36\n",
      "239-\n",
      "241-+27\n",
      "239-\n",
      "241-*.36\n",
      "239-\n",
      "241-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "361-+27\n",
      "239-\n",
      "241-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "241-+27\n",
      "239-\n",
      "241-'3\n",
      "239-\n",
      "241-$0\n",
      "239-\n",
      "241-'3\n",
      "239-\n",
      "241-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "121-+37\n",
      "479-\n",
      "1-+37\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-%,1\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-'.3\n",
      "479-\n",
      "1-$+0\n",
      "479-\n",
      "1-+27\n",
      "479-\n",
      "1-*.36\n",
      "479-\n",
      "1-+27\n",
      "239-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "1-+27\n",
      "119-\n",
      "121-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-36'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-36'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6:'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7+\n",
      "479-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-+\n",
      "1-+7\n",
      "79-\n",
      "1-7+\n",
      "239-+\n",
      "1-+7\n",
      "119-+\n",
      "1-+7\n",
      "119-\n",
      "1-6:'\n",
      "119-'\n",
      "1-'6\n",
      "119-'\n",
      "1-'6\n",
      "239-\n",
      "1-7\n",
      "479-\n",
      "1-6\n",
      "479-\n",
      "1-4\n",
      "479-\n",
      "1-2\n",
      "479-\n",
      "1-0\n",
      "479-\n",
      "1-.\n",
      "479-\n",
      "1--\n",
      "479-\n",
      "1-,\n",
      "479-\n",
      "1-+\n",
      "479-\n",
      "1--\n",
      "239-\n",
      "1-.\n",
      "79-\n",
      "1-.\n",
      "79-\n",
      "1-.\n",
      "79-\n",
      "1-0\n",
      "239-\n",
      "1-2\n",
      "119-\n",
      "1-2\n",
      "119-\n",
      "1-3\n",
      "119-\n",
      "1-3\n",
      "119-\n",
      "1-4\n",
      "239-\n",
      "1-5\n",
      "479-\n",
      "1-6\n",
      "239-\n",
      "1-6\n",
      "79-\n",
      "1-6\n",
      "79-\n",
      "1-6\n",
      "79-\n",
      "1-7\n",
      "239-\n",
      "1-7\n",
      "119-\n",
      "1-7\n",
      "119-\n",
      "1-9\n",
      "119-\n",
      "1-9\n",
      "119-\n",
      "1-9\n",
      "239-\n",
      "1-:&\n",
      "79-&\n",
      "1-&:\n",
      "79-&\n",
      "1-&:\n",
      "79-\n",
      "1-0;'\n",
      "79-'\n",
      "1-'.\n",
      "79-'\n",
      "1-'0\n",
      "79-'\n",
      "1-'2\n",
      "79-'\n",
      "1-'0\n",
      "79-'\n",
      "1-'2\n",
      "79-'\n",
      "1-'3\n",
      "79-'\n",
      "1-'2\n",
      "79-'\n",
      "1-'3\n",
      "79-'\n",
      "1-'5\n",
      "79-'\n",
      "1-'3\n",
      "79-'\n",
      "1-'5\n",
      "79-'\n",
      "1-'6\n",
      "79-'\n",
      "1-'5\n",
      "79-'\n",
      "1-'6\n",
      "79-'\n",
      "1-'7\n",
      "79-'\n",
      "1-'6\n",
      "79-'\n",
      "1-'7\n",
      "79-'\n",
      "1-'9\n",
      "79-'\n",
      "1-'7\n",
      "79-'\n",
      "1-'9\n",
      "79-'\n",
      "1-':\n",
      "79-'\n",
      "1-'7\n",
      "79-'\n",
      "1-'9\n",
      "79-'\n",
      "1-':\n",
      "79-'\n",
      "1-'<\n",
      "79-'\n",
      "1-'>\n",
      "79-'\n",
      "1440-\n",
      "1-+27\n",
      "479-\n",
      "1-+27\n",
      "239-\n",
      "1-+27\n",
      "79-\n",
      "1-+27\n",
      "79-\n",
      "1-+27\n",
      "79-\n",
      "1-'.3\n",
      "119-\n",
      "1-'.3\n",
      "119-\n",
      "241-\u001f&+\n",
      "239-\n",
      "241-'.3\n",
      "479-\n",
      "1-\u001f&+\n",
      "239-\n",
      "1-'3\n",
      "239-\n",
      "1-&2\n",
      "239-\n",
      "1-\u001f&+\n",
      "239-\n"
     ]
    }
   ],
   "source": [
    "#print(instrument1)\n",
    "#convert to format\n",
    "x = 0\n",
    "arr = []\n",
    "f = open(\"test.txt\",\"w\")\n",
    "while x < len(instrument2):\n",
    "    time = instrument2[x][1]\n",
    "    if x == 0:\n",
    "        line = str(instrument2[x][1]) + \"-\"\n",
    "    elif x > 0:\n",
    "        line = str(instrument2[x][1]-instrument2[x-1][1]) + \"-\"\n",
    "    flag = 0\n",
    "    while x < len(instrument2) and time == instrument2[x][1]:\n",
    "        if instrument2[x][4] != 0:\n",
    "            if arr.count(instrument2[x][3]) == 0:\n",
    "                arr.append(instrument2[x][3])\n",
    "#            arr[instrument2[x][3]] = 1\n",
    "        elif instrument2[x][4] == 0:\n",
    "            if arr.count(instrument2[x][3]) == 1:\n",
    "                arr.remove(instrument2[x][3])\n",
    "#            arr[instrument2[x][3]] = 0\n",
    "        flag = 1\n",
    "        x += 1\n",
    "    for i in arr:\n",
    "        line += chr(i)\n",
    "    if flag == 1:\n",
    "        print(line)\n",
    "        f.write(line+\" \")\n",
    "        continue\n",
    "    x += 1\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:  479- 1-7+ 239\n",
      "Encoded:  [18 21 23 11  1 15 11 21  9  1 16 17 23]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"test.txt\",\"r\")\n",
    "lines = file.read()\n",
    "\n",
    "vocab = sorted(set(lines))\n",
    "\n",
    "#Creating a mapping from characters to ints as opposed to words to ints from the text classification file\n",
    "#characters is easier as there is a much smaller range of characters (a-z,A-Z,.,!) etc. as opposed to range of words\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(lines):\n",
    "    return np.array([char2idx[c] for c in lines])\n",
    "\n",
    "text_as_int = text_to_int(lines)\n",
    "\n",
    "print(\"TEXT: \",lines[:13])\n",
    "print(\"Encoded: \",text_to_int(lines[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479- 1-7+ 239\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints):\n",
    "    #this try is meant in case ints is not already a numpy array, it will convert it into one \n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except: #otherwise just pass on the numpy conversion\n",
    "        pass\n",
    "    return ''.join(idx2char[ints]) #create empty string and join all characters\n",
    "\n",
    "print(int_to_text(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our task is to feed the model a sequence and have it return the next character\n",
    "# this means we have to split our text data into many shorter sequences that we can pass to the model\n",
    "# the training examples will use a sequence length as input and sequence length sequence as the output where that\n",
    "# sequence is the orignal sequence but shifted over one letter to the right Ex.\n",
    "# input: Hell , output: ello\n",
    "\n",
    "seq_length = 20 # length of sequence for a training example\n",
    "examples_per_epoch = len(lines)//(seq_length+1) #we need to have 21 characters per training example\n",
    "\n",
    "#Creating training examples/ targets\n",
    "#it will convert our entire string dataset (converted from chars to int) into characters \n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we use the batch method to turn this stream of chars into batches of desired length\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True) #drop_remainder means any characters after length of 21 get dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to use these sequences of length 21 and split them into input and output\n",
    "#this basically creates those input examples we needed\n",
    "def split_input_target(chunk): # ex: hello\n",
    "    input_text = chunk[:-1] #hell\n",
    "    target_text = chunk[1:] #ello\n",
    "    return input_text, target_text # hell, ello\n",
    "\n",
    "dataset = sequences.map(split_input_target) # we use a map to apply the above function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Example\n",
      "\n",
      "Input\n",
      "479- 1-7+ 239-+ 1-+7\n",
      "\n",
      "Output\n",
      "79- 1-7+ 239-+ 1-+7 \n",
      "\n",
      "\n",
      "Example\n",
      "\n",
      "Input\n",
      "79-+ 1-+7 79-+ 1-+7 \n",
      "\n",
      "Output\n",
      "9-+ 1-+7 79-+ 1-+7 7\n"
     ]
    }
   ],
   "source": [
    "for x,y in dataset.take(2):\n",
    "    print(\"\\n\\nExample\\n\")\n",
    "    print(\"Input\")\n",
    "    print(int_to_text(x))\n",
    "    print(\"\\nOutput\")\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "# Now we need to make training batches\n",
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab) #vocab is a number of unique characters\n",
    "print(VOCAB_SIZE)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# Buffer size to shuffle that dataset\n",
    "# (Tf data is designed to work with possibly infinite sequences\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           9472      \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 37)            37925     \n",
      "=================================================================\n",
      "Total params: 5,294,373\n",
      "Trainable params: 5,294,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now its time to build the model. We will be using and embedding layer, a LSTM layer and one dense layer\n",
    "# that contains a node for each unique character in our training data. The dense layer will give us a probability distribution over all nodes\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                 batch_input_shape=[batch_size,None]), #none means we dont know how long the sequences will be in each batch. All we know is we will have 64 entries in each batch( aka training examples) \n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences=True, #returns the intermediate stage at every step so that we can see what the model is seeing at the intermediate steps, not just the final stage   \n",
    "                             stateful=True,\n",
    "                             recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size) \n",
    "        # dense layer which contains the amount of vocabulary size nodes. We do this because we want final layer to have the amount of nodes = amount of characters in vocab. This way every single node can represent a probability distribution that that character comes next    \n",
    "    ])\n",
    "    return model\n",
    "    \n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS,BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20, 37) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "# we will create our own loss function for this problem. This is because our model will output a (64, sequence_length, 37)\n",
    "# shaped tensor that represents the probability distribution of each character at each timestep for every sequence in the batch\n",
    "\n",
    "# However, before we do that, lets have a look at a sample input and output from our untrained model. This is so we can understand what \n",
    "# the model is actually giving us\n",
    "# The model we created accepts a batch of 64 training examples that are of length 20\n",
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch) # ask our model for a prediction on out first batch of training data\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  #print out the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 1.39007985e-03  2.96485098e-03  1.92812306e-03 ... -3.70148569e-03\n",
      "    3.17208190e-03  1.59287360e-04]\n",
      "  [-1.88999658e-03 -8.59820284e-06  6.57131104e-03 ... -5.07274596e-03\n",
      "    1.51942053e-03 -2.87097949e-03]\n",
      "  [ 2.37131864e-03 -6.53473195e-04  9.06627718e-03 ... -4.13072761e-03\n",
      "   -1.63248880e-03 -9.54523496e-03]\n",
      "  ...\n",
      "  [-4.81056049e-04 -3.22813727e-03  1.20810214e-02 ... -2.70876125e-03\n",
      "   -6.52535586e-03 -1.17533645e-02]\n",
      "  [-6.68086950e-03 -3.24738142e-03  5.66080585e-03 ... -7.45295500e-03\n",
      "   -4.71504545e-03 -7.02633243e-03]\n",
      "  [-4.30932362e-03  3.18813464e-03  6.51056296e-04 ... -2.58483808e-03\n",
      "   -3.99496593e-03 -4.66809794e-03]]\n",
      "\n",
      " [[-4.61607520e-03 -4.93816333e-04 -4.40974440e-03 ... -4.59854584e-03\n",
      "    9.16280551e-04  1.38075871e-03]\n",
      "  [-1.35142694e-03  5.30548021e-03 -7.98305683e-03 ...  2.71886995e-04\n",
      "    1.17093860e-03  1.36146811e-03]\n",
      "  [ 1.11750467e-03  2.95959646e-04 -7.31500564e-03 ...  1.27352623e-03\n",
      "    7.72925373e-03  3.22219683e-04]\n",
      "  ...\n",
      "  [-1.26781994e-02 -5.78862336e-03 -4.40301001e-03 ... -2.67926836e-03\n",
      "   -4.38718311e-03 -2.15435540e-03]\n",
      "  [-7.53037632e-03  2.02161074e-03 -7.12345541e-03 ...  1.04265148e-03\n",
      "   -2.90964684e-03 -1.06807519e-03]\n",
      "  [-1.15879928e-03  1.40668545e-03 -5.04399301e-04 ...  8.37306725e-04\n",
      "   -5.02926717e-03 -7.52356183e-03]]\n",
      "\n",
      " [[ 4.96031530e-03 -1.81179406e-04  3.85959796e-03 ... -6.87620952e-04\n",
      "   -2.93677999e-03 -7.02730520e-03]\n",
      "  [-1.52816391e-03 -5.90851530e-04 -1.81051984e-03 ... -5.61045390e-03\n",
      "   -1.26882666e-03 -3.66329495e-03]\n",
      "  [-6.41798927e-03 -3.74078343e-04 -5.32423658e-03 ... -8.18567351e-03\n",
      "   -2.25740019e-04 -1.91814825e-03]\n",
      "  ...\n",
      "  [-5.71560860e-03 -2.70928023e-04 -3.64639377e-03 ... -2.93016480e-03\n",
      "   -3.20593058e-03 -3.01042409e-03]\n",
      "  [-3.53763392e-03  5.68385143e-03 -7.01026805e-03 ...  1.69700163e-03\n",
      "   -2.29478255e-03 -1.04376918e-03]\n",
      "  [ 7.48711172e-04  6.14167098e-03 -2.41000263e-04 ... -1.96890463e-03\n",
      "   -2.24989746e-03  3.28956870e-04]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-4.61607520e-03 -4.93816333e-04 -4.40974440e-03 ... -4.59854584e-03\n",
      "    9.16280551e-04  1.38075871e-03]\n",
      "  [-1.35142694e-03  5.30548021e-03 -7.98305683e-03 ...  2.71886995e-04\n",
      "    1.17093860e-03  1.36146811e-03]\n",
      "  [-2.69117835e-03  1.61458529e-03 -7.35606160e-03 ... -1.19924708e-03\n",
      "   -1.78268529e-03 -6.09232811e-04]\n",
      "  ...\n",
      "  [ 7.50568928e-04 -9.38737299e-03  1.05614085e-02 ...  7.34950136e-03\n",
      "   -5.47393318e-03 -8.01231619e-03]\n",
      "  [-3.02544213e-03 -1.42844263e-02  7.94876460e-03 ...  3.57549358e-03\n",
      "   -6.35289215e-03 -6.05079019e-03]\n",
      "  [ 1.24245096e-04 -6.16193982e-03  2.35506310e-03 ...  4.14539455e-03\n",
      "   -3.87923350e-03 -2.65589333e-03]]\n",
      "\n",
      " [[ 4.96031530e-03 -1.81179406e-04  3.85959796e-03 ... -6.87620952e-04\n",
      "   -2.93677999e-03 -7.02730520e-03]\n",
      "  [ 5.58474753e-03 -3.96416988e-03  2.42591323e-03 ... -4.12747264e-03\n",
      "   -3.28816706e-03 -1.17095178e-02]\n",
      "  [ 2.47034756e-03 -5.59969433e-03  5.20399399e-03 ...  2.41379580e-03\n",
      "   -9.17958096e-04 -1.00751230e-02]\n",
      "  ...\n",
      "  [-4.07932792e-04  3.73416208e-03 -6.21248642e-03 ... -6.20019622e-04\n",
      "   -5.84107824e-04 -3.91522713e-04]\n",
      "  [ 1.07208919e-03  9.63722821e-04 -4.27893456e-03 ... -8.46736133e-04\n",
      "   -3.84808448e-03 -4.06744686e-04]\n",
      "  [-9.57629178e-04  1.62495975e-03 -3.36495205e-03 ...  5.90015110e-03\n",
      "   -8.34248774e-03 -2.38373550e-03]]\n",
      "\n",
      " [[ 4.96031530e-03 -1.81179406e-04  3.85959796e-03 ... -6.87620952e-04\n",
      "   -2.93677999e-03 -7.02730520e-03]\n",
      "  [ 1.65201840e-03 -2.62823002e-03  6.08318718e-03 ...  4.88285813e-03\n",
      "   -9.61888116e-04 -6.53360272e-03]\n",
      "  [-2.90867360e-03 -4.34109382e-03  5.28373523e-03 ...  8.20644666e-03\n",
      "   -6.22509047e-03 -5.30286180e-03]\n",
      "  ...\n",
      "  [ 5.50432969e-03 -1.56437443e-03  8.58494639e-03 ...  2.39957846e-03\n",
      "   -7.87982997e-03 -3.62768257e-03]\n",
      "  [ 3.18066217e-04 -3.85401119e-03  7.21335365e-03 ...  8.13839398e-03\n",
      "   -1.18838549e-02 -2.51111062e-03]\n",
      "  [-6.00235676e-03 -7.31846783e-04  4.55655809e-03 ...  2.54088175e-03\n",
      "   -7.60485465e-03  6.23246655e-04]]], shape=(64, 20, 37), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "tf.Tensor(\n",
      "[[ 1.39007985e-03  2.96485098e-03  1.92812306e-03  7.04883598e-03\n",
      "   8.80094618e-03  3.23823956e-03 -1.56151643e-03  4.22026170e-03\n",
      "  -2.19877297e-03  1.84655865e-03 -1.89694366e-03  1.73168257e-03\n",
      "  -1.40565471e-03  3.11409030e-03  8.84319004e-03 -2.07967032e-03\n",
      "   1.08891435e-03 -7.92788342e-04 -6.42442843e-04  4.12447518e-03\n",
      "   6.99645001e-03 -1.12493895e-03 -1.27321912e-03 -1.64494349e-03\n",
      "  -4.68928553e-03 -2.07526330e-03 -2.10615294e-03  6.62319828e-03\n",
      "  -2.68733362e-03  8.98838683e-04  3.72589193e-03  3.14078713e-03\n",
      "   1.01604103e-03  7.47614773e-03 -3.70148569e-03  3.17208190e-03\n",
      "   1.59287360e-04]\n",
      " [-1.88999658e-03 -8.59820284e-06  6.57131104e-03  8.12127069e-03\n",
      "   4.04820126e-03  2.45730998e-03 -9.55392607e-04 -1.52095268e-03\n",
      "   2.68705655e-03  2.32883985e-03 -4.41759266e-03  5.31992409e-03\n",
      "   1.41919311e-03 -3.75410705e-03  1.41310375e-02 -5.94105478e-03\n",
      "   5.39265200e-03  4.71603591e-03  4.65417560e-03  3.19975521e-03\n",
      "   3.71325458e-03  2.34903442e-03 -1.07369397e-03 -5.27236611e-03\n",
      "   5.03750378e-03  3.24672833e-03  1.94754940e-03  8.64675734e-03\n",
      "  -6.39744475e-03  1.41805678e-03  6.89826068e-03 -2.68274802e-04\n",
      "   4.23802575e-03  7.58470502e-03 -5.07274596e-03  1.51942053e-03\n",
      "  -2.87097949e-03]\n",
      " [ 2.37131864e-03 -6.53473195e-04  9.06627718e-03  4.30748239e-03\n",
      "   9.33150062e-04  9.42767831e-04 -3.72402929e-03 -1.10606616e-03\n",
      "   1.43642095e-03  2.60664849e-03 -3.04013398e-03  3.50905000e-03\n",
      "   8.21734197e-04 -2.07144953e-03  6.54412899e-03 -3.35017568e-03\n",
      "   4.85705491e-03  3.63496784e-03  7.97733851e-03  2.03371560e-03\n",
      "   5.10995090e-03  6.78487681e-03 -2.82808440e-03 -1.80309871e-03\n",
      "   7.29310093e-04 -1.43530313e-04 -7.95470318e-04  5.52056404e-03\n",
      "  -4.37745638e-03 -4.05070046e-03  6.39138836e-03  1.84516481e-03\n",
      "  -2.14142865e-03  3.09875514e-03 -4.13072761e-03 -1.63248880e-03\n",
      "  -9.54523496e-03]\n",
      " [-1.11112092e-03 -3.19578522e-03  1.04684308e-02  3.84643348e-03\n",
      "  -1.30883418e-05  6.54686708e-04 -2.47835601e-03 -3.89853725e-03\n",
      "  -5.63626550e-03  5.11877891e-03  4.70104162e-03  9.93489753e-03\n",
      "  -3.88374343e-03 -7.94684142e-03  7.82924425e-03  4.35675401e-03\n",
      "   6.71228115e-03  3.56285670e-03  8.51712469e-03  1.77317706e-03\n",
      "   1.15348492e-02  1.49199716e-03 -1.65398186e-03  3.27220256e-03\n",
      "  -1.13095017e-03  1.45037437e-03 -8.72907136e-03  1.42536976e-03\n",
      "  -5.35218464e-03 -3.08755971e-03  4.57364600e-03 -1.58915436e-03\n",
      "  -3.61460797e-03  1.48975477e-03  2.42578518e-03 -7.21262768e-06\n",
      "  -8.69302638e-03]\n",
      " [-4.70973738e-03 -8.97588395e-03  7.41385529e-03 -1.85722718e-04\n",
      "   3.52179748e-04  1.66348484e-03  1.45583414e-03  2.87180394e-03\n",
      "   1.26806030e-04  9.09956545e-03  8.52215104e-03 -3.05951666e-03\n",
      "  -9.93079273e-04 -2.96856253e-03  8.45495984e-03  4.36172727e-03\n",
      "  -4.90034930e-03  8.37036408e-04  2.38253735e-03  1.20886462e-03\n",
      "   9.59875993e-03 -1.41175208e-03 -3.35541554e-04 -1.30482833e-03\n",
      "   5.88547112e-03 -3.18763265e-03 -1.29058110e-02  2.43817270e-03\n",
      "   5.92155848e-03  4.52358043e-04  9.87014035e-04  3.08421208e-03\n",
      "  -2.51732231e-03 -2.95162201e-03 -2.41918999e-04 -2.20649643e-03\n",
      "  -7.76301697e-03]\n",
      " [-1.12244685e-03 -1.54902344e-03  1.48788700e-03 -4.57803439e-03\n",
      "   2.83887074e-03  6.15209434e-03 -7.06487452e-04  1.43441709e-03\n",
      "   3.96205229e-04  2.61620502e-03  4.34967689e-03 -3.09980544e-03\n",
      "   2.30670883e-03 -4.14866675e-03  6.70623779e-03 -2.52137426e-04\n",
      "   3.22947954e-03  3.01292259e-03 -3.25937918e-03  8.37943517e-05\n",
      "   6.15059398e-03 -5.76025713e-03 -1.16666325e-03  8.85958085e-04\n",
      "   1.75261090e-03 -6.78967685e-04 -3.92117677e-03  4.13357234e-03\n",
      "   8.32482940e-04 -2.15625158e-03 -6.98659220e-04  2.95680342e-03\n",
      "   7.82297691e-04 -1.99182006e-03  1.19589316e-03 -9.63740051e-04\n",
      "  -5.10299532e-03]\n",
      " [-3.20494943e-03 -3.92865669e-03  7.08059035e-03  3.85476160e-04\n",
      "   1.35171646e-03  4.62519377e-03 -2.48404103e-04 -4.08666814e-03\n",
      "   3.45866568e-03  1.83073350e-03  1.73703255e-03  9.29560396e-04\n",
      "   3.88916908e-03 -8.89111962e-03  1.17240418e-02 -5.20291412e-03\n",
      "   7.28487317e-03  7.46529456e-03  2.34296103e-03 -6.19583763e-04\n",
      "   3.13785160e-03 -1.86817138e-03 -1.81200297e-03 -3.21338442e-03\n",
      "   1.13536622e-02  4.85233311e-03  5.67570096e-04  6.08827360e-03\n",
      "  -3.04400083e-03 -4.63587930e-04  4.70591430e-03 -1.25967036e-03\n",
      "   3.95879149e-03  1.33507734e-03 -2.21386063e-03 -1.36940181e-03\n",
      "  -6.52900105e-03]\n",
      " [ 1.59358932e-03 -4.06795461e-03  9.98496544e-03 -8.57274630e-04\n",
      "  -5.62879723e-05  2.54359492e-03 -2.97821476e-03 -3.51853622e-03\n",
      "   1.41718995e-03  1.51147717e-03  2.49661179e-03 -4.02307051e-04\n",
      "   2.48565711e-03 -5.45583945e-03  3.95367155e-03 -3.31528345e-03\n",
      "   6.66764565e-03  5.48881944e-03  5.82999177e-03 -1.18607469e-03\n",
      "   4.86619864e-03  3.16900178e-03 -3.93360900e-03 -2.26240838e-04\n",
      "   6.57906709e-03  1.66595366e-03 -1.56338350e-03  3.02288705e-03\n",
      "  -1.29332859e-03 -5.32944081e-03  5.49724186e-03  3.75847332e-04\n",
      "  -2.56492430e-03 -8.91478499e-04 -2.43527675e-03 -4.06860374e-03\n",
      "  -1.18813105e-02]\n",
      " [-4.82206466e-03 -4.04903200e-03  3.64275463e-03  1.69833167e-03\n",
      "   3.24820681e-03  6.34987839e-03 -9.23099834e-03 -7.29148043e-03\n",
      "   5.06678224e-03  8.52247467e-04 -3.94935720e-04  1.42832065e-03\n",
      "   5.74369542e-03 -4.53904644e-03 -1.13987189e-03 -6.48765080e-03\n",
      "   6.59160689e-03 -1.61163136e-03 -1.51575659e-03 -1.28313899e-03\n",
      "   3.56015237e-03  5.17640496e-03 -2.11548805e-03 -5.06234774e-03\n",
      "   8.96863174e-03 -1.05876883e-03 -1.75269344e-03  4.69063967e-03\n",
      "   6.90330798e-03 -5.35708852e-04  2.55269813e-03  1.63060299e-03\n",
      "  -3.32466606e-03  5.21878805e-03 -7.07859593e-03 -2.50154780e-03\n",
      "  -7.18669128e-03]\n",
      " [-2.66009313e-03  2.42680125e-03 -1.24792662e-03 -1.73784676e-03\n",
      "   5.10427728e-03  8.55805539e-03 -7.32885906e-03 -6.12862455e-03\n",
      "   3.41842510e-03 -2.74366536e-03 -1.91582390e-03  6.77854521e-04\n",
      "   6.34998456e-03 -5.45754563e-03 -5.70961740e-04 -8.64570215e-03\n",
      "   1.22425016e-02  7.39000388e-04 -6.11541048e-03 -1.93121168e-03\n",
      "   2.24059029e-03 -2.56146654e-04 -1.55329320e-03 -1.35486166e-03\n",
      "   4.51692892e-03  2.40007415e-03  3.25191161e-03  3.14758532e-03\n",
      "   1.93742593e-03 -3.49496282e-03  4.52840119e-04  5.17674722e-04\n",
      "   8.17441614e-04  4.74248547e-03 -2.12730491e-03 -2.05301959e-03\n",
      "  -4.84917965e-03]\n",
      " [-5.45283733e-03 -5.14070503e-04  5.32646850e-03  3.44926724e-03\n",
      "   2.95988051e-03  5.55459736e-03 -4.29087412e-03 -9.42057837e-03\n",
      "   5.25035616e-03 -1.51729770e-03 -2.61764112e-03  4.06174175e-03\n",
      "   6.34528371e-03 -9.91465990e-03  6.07126206e-03 -1.20192161e-02\n",
      "   1.45239197e-02  5.33670280e-03  3.16170277e-04 -2.29038158e-03\n",
      "   7.20520155e-04  2.42976099e-03 -1.21179735e-03 -4.54244856e-03\n",
      "   1.39080053e-02  8.28476809e-03  5.11871139e-03  3.33014945e-03\n",
      "  -2.03940528e-03 -1.92563923e-03  5.60588855e-03 -4.10691043e-03\n",
      "   4.57206788e-03  6.74347207e-03 -3.48416902e-03 -3.04511003e-03\n",
      "  -6.51180930e-03]\n",
      " [-4.57709050e-03  2.07262323e-03  7.10444897e-03  1.04625495e-02\n",
      "   1.04126725e-02  6.74005505e-03 -4.26267553e-03 -3.09369480e-03\n",
      "   4.32900386e-04  1.15516246e-03 -2.62289052e-03  4.17390978e-03\n",
      "   1.37971411e-03 -4.59587201e-03  1.27674267e-02 -1.29020046e-02\n",
      "   1.29292719e-02  2.34082807e-03 -2.70865043e-04  2.11623055e-03\n",
      "   9.34464764e-03 -2.30025849e-04 -1.92969851e-03 -4.39805724e-03\n",
      "   7.35490350e-03  5.98784909e-03  8.93639866e-04  6.30171644e-03\n",
      "  -3.51869897e-03 -1.85779412e-04  9.00506601e-03 -1.36669853e-03\n",
      "   4.90439730e-03  1.32975681e-02 -5.58389956e-03  1.39087788e-04\n",
      "  -4.68402449e-03]\n",
      " [-4.04499413e-04  8.90077092e-04  1.03599718e-02  6.06631581e-03\n",
      "   5.51070692e-03  4.05353494e-03 -6.20135665e-03 -2.03508371e-03\n",
      "  -8.29713652e-04  1.55317597e-03 -1.77221000e-03  2.67401268e-03\n",
      "   1.79660041e-04 -1.78919337e-03  5.36041008e-03 -1.06765758e-02\n",
      "   1.07275145e-02  2.32465984e-03  3.97711108e-03  1.42600201e-03\n",
      "   9.25176032e-03  4.54296125e-03 -2.52089091e-03 -9.71168978e-04\n",
      "   4.65092761e-03  2.83478014e-03 -1.50598749e-03  2.70549674e-03\n",
      "  -1.90160493e-03 -5.16817300e-03  7.86980055e-03 -7.55065703e-04\n",
      "  -1.86439697e-03  8.10679607e-03 -4.23270371e-03 -3.67954304e-03\n",
      "  -1.06691029e-02]\n",
      " [-3.87626002e-03 -1.98080856e-03  1.21797305e-02  5.28753269e-03\n",
      "   3.09926365e-03  2.78310664e-03 -4.17331699e-03 -4.43409756e-03\n",
      "  -7.65423151e-03  4.25838493e-03  5.42658567e-03  9.36008897e-03\n",
      "  -4.60154144e-03 -7.10739195e-03  6.92969374e-03 -2.74363300e-03\n",
      "   1.12960422e-02  2.80435104e-03  5.32263517e-03  1.42457010e-03\n",
      "   1.45899020e-02 -3.67766945e-04 -5.41398767e-04  3.89095419e-03\n",
      "   3.34926927e-03  4.43832483e-03 -9.23273899e-03 -1.65181421e-03\n",
      "  -3.18693789e-03 -3.84006556e-03  5.59594855e-03 -4.95040603e-03\n",
      "  -3.46675445e-03  5.68454061e-03  2.46476894e-03 -2.47533433e-03\n",
      "  -9.25683882e-03]\n",
      " [-7.37736514e-03 -7.94305652e-03  9.38956067e-03  9.94723290e-04\n",
      "   2.32068496e-03  3.03240307e-03  3.88679560e-04  2.53662141e-03\n",
      "  -1.51486380e-03  8.39970168e-03  8.85013584e-03 -3.49600986e-03\n",
      "  -1.51910679e-03 -1.93479878e-03  7.79524725e-03 -2.23994395e-03\n",
      "  -1.30645395e-03  3.23885120e-04 -1.39635871e-04  8.78959429e-04\n",
      "   1.18359001e-02 -2.85533117e-03  1.28453737e-03 -1.02061639e-03\n",
      "   1.03170257e-02 -2.41630594e-04 -1.32341888e-02 -7.42026139e-04\n",
      "   7.74244871e-03 -1.14000170e-04  1.60379207e-03 -6.55589625e-04\n",
      "  -2.41792854e-03  5.42957569e-04 -1.84755132e-04 -4.89348173e-03\n",
      "  -8.01678374e-03]\n",
      " [-3.61666339e-03 -6.12694770e-04  3.62520479e-03 -3.58600193e-03\n",
      "   3.92210437e-03  6.95360545e-03 -1.30814977e-03  1.24588807e-03\n",
      "  -8.59607942e-04  2.05835607e-03  4.31929622e-03 -3.46295885e-03\n",
      "   2.04861211e-03 -3.11172451e-03  6.24629296e-03 -6.22317707e-03\n",
      "   6.03788253e-03  2.61888281e-03 -5.23528690e-03 -2.26583797e-04\n",
      "   7.77680147e-03 -6.86986698e-03  7.10816123e-04  8.92153010e-04\n",
      "   5.92940673e-03  2.07134779e-03 -4.16310318e-03  1.00134127e-03\n",
      "   2.39029084e-03 -2.56319204e-03 -3.92480637e-04 -8.33263155e-04\n",
      "   8.87713628e-04  9.29211848e-04  1.17133569e-03 -3.68261617e-03\n",
      "  -5.17985038e-03]\n",
      " [-5.48040122e-03 -3.04448674e-03  9.23171546e-03  1.18023856e-03\n",
      "   1.80502341e-03  4.96925972e-03 -4.77515510e-04 -4.19823825e-03\n",
      "   2.55389512e-03  1.37639139e-03  1.45300664e-03  5.95695106e-04\n",
      "   3.84954503e-03 -7.98510108e-03  1.14349518e-02 -1.04803974e-02\n",
      "   9.56618041e-03  7.08852708e-03  8.26461939e-04 -9.23289917e-04\n",
      "   4.29167598e-03 -2.71322718e-03  1.98012771e-04 -3.41048930e-03\n",
      "   1.50880413e-02  7.35133886e-03  3.94898467e-04  3.06747225e-03\n",
      "  -1.75815425e-03 -7.72908330e-04  4.74139862e-03 -4.92940936e-03\n",
      "   4.12131567e-03  3.78741557e-03 -2.36978894e-03 -4.01215116e-03\n",
      "  -6.48659747e-03]\n",
      " [-4.81056049e-04 -3.22813727e-03  1.20810214e-02 -2.35324726e-04\n",
      "  -2.67596915e-05  2.56230612e-03 -2.96048704e-03 -3.58710531e-03\n",
      "   7.64783705e-04  1.09946146e-03  2.05858191e-03 -6.95711991e-04\n",
      "   2.64118821e-03 -4.71392553e-03  3.75866471e-03 -7.93263130e-03\n",
      "   8.52133892e-03  5.09047788e-03  4.68748622e-03 -1.51257776e-03\n",
      "   5.69654908e-03  2.53002974e-03 -1.95616623e-03 -5.54849976e-04\n",
      "   9.79539100e-03  3.91887501e-03 -1.68225705e-03  1.34577509e-04\n",
      "  -2.75273807e-04 -5.55635383e-03  5.29462751e-03 -3.08773573e-03\n",
      "  -2.37398176e-03  1.17323408e-03 -2.70876125e-03 -6.52535586e-03\n",
      "  -1.17533645e-02]\n",
      " [-6.68086950e-03 -3.24738142e-03  5.66080585e-03  2.15858244e-03\n",
      "   2.97724921e-03  6.14621444e-03 -9.00289323e-03 -7.34479539e-03\n",
      "   4.63529630e-03  5.08166617e-04 -9.50993039e-04  1.17015233e-03\n",
      "   6.02236670e-03 -3.97512503e-03 -1.29765971e-03 -1.05041806e-02\n",
      "   8.12355522e-03 -2.03194469e-03 -2.36575073e-03 -1.62642379e-03\n",
      "   4.14259173e-03  4.70870594e-03 -2.15674983e-04 -5.44258347e-03\n",
      "   1.16779245e-02  9.05937748e-04 -1.84496539e-03  2.00552191e-03\n",
      "   7.71046523e-03 -7.06910389e-04  2.16501020e-03 -1.55129062e-03\n",
      "  -3.11781419e-03  7.00077601e-03 -7.45295500e-03 -4.71504545e-03\n",
      "  -7.02633243e-03]\n",
      " [-4.30932362e-03  3.18813464e-03  6.51056296e-04 -1.41635584e-03\n",
      "   4.63811774e-03  8.19349010e-03 -6.97927643e-03 -6.15463266e-03\n",
      "   3.14858253e-03 -3.07008158e-03 -2.53462489e-03  4.43821773e-04\n",
      "   6.69482164e-03 -5.06368978e-03 -6.82169106e-04 -1.21456860e-02\n",
      "   1.35088889e-02  2.90257507e-04 -6.75045792e-03 -2.28567282e-03\n",
      "   2.63053365e-03 -5.63277863e-04  2.01847317e-04 -1.76029513e-03\n",
      "   6.76124031e-03  4.10340959e-03  3.16501269e-03  6.91227615e-04\n",
      "   2.58191535e-03 -3.62180592e-03 -8.07214528e-05 -2.37060525e-03\n",
      "   1.00531406e-03  6.29941374e-03 -2.58483808e-03 -3.99496593e-03\n",
      "  -4.66809794e-03]], shape=(20, 37), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#lets examine one prediction\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)\n",
    "#notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "tf.Tensor(\n",
      "[ 0.00139008  0.00296485  0.00192812  0.00704884  0.00880095  0.00323824\n",
      " -0.00156152  0.00422026 -0.00219877  0.00184656 -0.00189694  0.00173168\n",
      " -0.00140565  0.00311409  0.00884319 -0.00207967  0.00108891 -0.00079279\n",
      " -0.00064244  0.00412448  0.00699645 -0.00112494 -0.00127322 -0.00164494\n",
      " -0.00468929 -0.00207526 -0.00210615  0.0066232  -0.00268733  0.00089884\n",
      "  0.00372589  0.00314079  0.00101604  0.00747615 -0.00370149  0.00317208\n",
      "  0.00015929], shape=(37,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#and finally we will look at a prediction at the first timestep\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)\n",
    "# and of course its 37 values representing the probability of each character occuring next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+3F*&\\x1f,!,A!)%:4FF85:'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to determine the predicted character we need to sample the output distribution (pick a value based on probability)\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "# now we can reshape that array and convert all ints to numbers to see the actual chars\n",
    "sampled_indices = np.reshape(sampled_indices, (1,-1))[0]\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars #and this is what the model predicted for training sequence 1\n",
    "\n",
    "#NOTE we dont just take max val from that distribution as we will get stuck in an infinite loop \n",
    "# where we just accept the biggest character so instead, we will pick a char (look up sampling a distibution, it doesnt gurantee that the char with the highest probability will be picked, it just uses those probabilities to pick it )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So now we need to make a loss function that can compare the output to the expected output\n",
    "# and give us some numeric value representing how close the two were\n",
    "def loss(labels, logits): #logit is probability distribution\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels,logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point we can think of our problem as a classification problem where model predicts the probability of each unique letter coming next\n",
    "model.compile(optimizer=\"adam\",loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to setup and configure our model to save checkpoints as it trains. This will allow us to load our model from a checkpoint \n",
    "# and continue training it\n",
    "#where checkpoints will be saved\n",
    "checkpoint_dir = 'ModelCheckPoints'\n",
    "\n",
    "#Name of checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 2\n"
     ]
    }
   ],
   "source": [
    "for num, _ in enumerate(data):\n",
    "    pass\n",
    "\n",
    "print(f'Number of elements: {num}')\n",
    "#steps_per_epoch = num+1 or data size +1 (most likely due to seq length +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 3.5062\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 3.1831\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.6906\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 2.5095\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.4034\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.3407\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 2.2910\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 2.2487\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 2.1923\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 2.1217\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 2.0373\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.9360\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.8321\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7369\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.6175\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.5147\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.4110\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.3359\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.2613\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.2057\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.1868\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.1470\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.1076\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0919\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.0811\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 1.0362\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.9789\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.9724\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.9220\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.9070\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8840\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8467\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8462\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8490\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.8156\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.7867\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7687\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7440\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7183\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7046\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.7056\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6929\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6638\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.6379\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6351\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.6155\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.6166\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.6045\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5721\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5749\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5774\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5594\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5541\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5516\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5229\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.5135\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5027\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5054\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4994\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4940\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.5043\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4836\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 8s 3s/step - loss: 0.4729\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4729\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4733\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4508\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4434\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4349\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4543\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4457\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4387\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4357\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4329\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4287\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4315\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4060\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4021\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.4159\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.4017\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3925\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3772\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3997\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3853\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3663\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3807\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3788\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.3628\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3621\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3708\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3495\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3829\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3566\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3530\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3613\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3550\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3395\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3393\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3537\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3304\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3453\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3406\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3364\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3270\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3310\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3152\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3254\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3106\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.3285\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3184\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3137\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3204\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3136\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.3169\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3029\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3039\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3056\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3093\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3047\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3029\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2936\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3111\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2979\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2940\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.3008\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.3045\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2898\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2905\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2830\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2830\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2861\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2830\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2760\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2878\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2885\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2867\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2834\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2756\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2786\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2771\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2960\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2722\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2709\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2709\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2699\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2678\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2784\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2610\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2675\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2615\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2772\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2653\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2655\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2650\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2540\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2596\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2666\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2586\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2687\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2594\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2526\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2486\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2440\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2485\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2485\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2529\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2684\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2504\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2475\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2551\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2669\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.2529\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2571\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2596\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2519\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 7s 2s/step - loss: 0.2537\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2495\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2452\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2426\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2495\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2512\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2470\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2457\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2571\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2400\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2477\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2449\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2394\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2531\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2522\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2502\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2383\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2420\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2372\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2451\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2388\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2394\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2349\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2482\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2485\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs=200, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll rebuild the model from a checkpoint using a batch_size of 1 so that we can feed one piece of text to the model and have it make a prediction\n",
    "#remember that the original batch size was 64 which means we would have to pass it 64 inputs aka sequences for it to work properly\n",
    "model = build_model(VOCAB_SIZE,EMBEDDING_DIM,RNN_UNITS, batch_size=1)\n",
    "# we rebuild to size 1 so that we can pass some sequence of whatever length we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once the model is finished training, we can find the latest checkpoint, that stores the models weights using the following\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    #Evaluation step (generating text using the learned model)\n",
    "    \n",
    "    #Number of characters to generate\n",
    "    num_generate = 800\n",
    "    \n",
    "    #Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string] # we have to preprocess the input sent by user and convert each char to an int/id\n",
    "    input_eval = tf.expand_dims(input_eval,0) # basically turn [9,8,7] to [[9,8,7]] because that is what is being expected as the input (1 batch which is basically a 2d array)\n",
    "    \n",
    "    #Empty string to store our results\n",
    "    text_generated = []\n",
    "    \n",
    "    #Lower temperatures results in more predictable text\n",
    "    #Higher temperatures results in more surprising text\n",
    "    #Experiement o find the best setting\n",
    "    temperature = 1.0\n",
    "    \n",
    "    #Here batch size == 1\n",
    "    model.reset_states() # we have to reset the state because when we rebuild the model its going to have stored the last state it remembered when training so we need to clear that before passing next text\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        #remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions,0) #basically go from [[]] to []\n",
    "        \n",
    "        #using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions/temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy() # this will sample the output from the model (REMEMBER HIGHER PROBABILITY DOESNT MEAN CORRECT CHOICE. SAMPLING MUST BE DONE)\n",
    "        \n",
    "        #We pass the predicted character as the next input to the model\n",
    "        #along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id],0) #are taking the predicted int and add it to input_Eval (same as str += 's' but with ints instead)\n",
    "        \n",
    "        text_generated.append(idx2char[predicted_id]) # converting the text which is from integers back into a string \n",
    "        \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type a starting string:  479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "479- 1-<0 239-0 1-0< 79-0 1-0< 79- 1-<0 239-0 1-0< 119-0 1-0< 119- 1-;/8 39- 1-6 79- 1-6 79- 1-7 239- 1-7 1-1= 119- 361-*6 239- 1-+27 479- 1-*36 479- 1-+27 240-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119- 1-+27 119- 361-+27 479- 1-*36 479- 1-$&+ 239- 1-<0 239-0 1-0< 79-0 1-0< 79- 1-'239- 1-&2 239- 1-\u001f&+ 239- 241-'3 239- 241-7 239- 124 479- 1-+27 479- 1-+27 479- 1-*36 479- 1-+27 240- ,6 79-+ 1-+7 79-+ 1-+7 79-+ 1-+7 79- 1-7+ 239-+ 1-+7 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+279- 1-%,1 479- 1-'.3 479- 1-'.3 479- 1-+27 479- 1-+27 479- 1-*36 479- 1-+27 240-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 119-+2 1-+27 11-1= 119- 1-0< 119- 1-+2 479- 1-'. 479- 1-+27 240-+27 119-+2 1-+27 119-+2 1-+27 1-+7 79-+ 1-+7 7\n"
     ]
    }
   ],
   "source": [
    "inp = input(\"Type a starting string: \")\n",
    "text_generated = generate_text(model,inp)\n",
    "print(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2, 480, Note_on_c, 0, 60, 100\n",
      "2, 480, Note_on_c, 0, 48, 100\n",
      "2, 719, Note_on_c, 0, 60, 0\n",
      "2, 720, Note_on_c, 0, 60, 100\n",
      "2, 799, Note_on_c, 0, 60, 0\n",
      "2, 800, Note_on_c, 0, 60, 100\n",
      "2, 879, Note_on_c, 0, 48, 0\n",
      "2, 879, Note_on_c, 0, 60, 0\n",
      "2, 880, Note_on_c, 0, 60, 100\n",
      "2, 880, Note_on_c, 0, 48, 100\n",
      "2, 1119, Note_on_c, 0, 60, 0\n",
      "2, 1120, Note_on_c, 0, 60, 100\n",
      "2, 1239, Note_on_c, 0, 60, 0\n",
      "2, 1240, Note_on_c, 0, 60, 100\n",
      "2, 1359, Note_on_c, 0, 48, 0\n",
      "2, 1359, Note_on_c, 0, 60, 0\n",
      "2, 1360, Note_on_c, 0, 59, 100\n",
      "2, 1360, Note_on_c, 0, 47, 100\n",
      "2, 1360, Note_on_c, 0, 56, 100\n",
      "2, 1399, Note_on_c, 0, 59, 0\n",
      "2, 1399, Note_on_c, 0, 47, 0\n",
      "2, 1399, Note_on_c, 0, 56, 0\n",
      "2, 1400, Note_on_c, 0, 54, 100\n",
      "2, 1479, Note_on_c, 0, 54, 0\n",
      "2, 1480, Note_on_c, 0, 54, 100\n",
      "2, 1559, Note_on_c, 0, 54, 0\n",
      "2, 1560, Note_on_c, 0, 55, 100\n",
      "2, 1799, Note_on_c, 0, 55, 0\n",
      "2, 1800, Note_on_c, 0, 55, 100\n",
      "2, 1920, Note_on_c, 0, 49, 0\n",
      "2, 1920, Note_on_c, 0, 61, 0\n",
      "2, 2281, Note_on_c, 0, 42, 100\n",
      "2, 2281, Note_on_c, 0, 54, 100\n",
      "2, 2520, Note_on_c, 0, 42, 0\n",
      "2, 2520, Note_on_c, 0, 54, 0\n",
      "2, 2521, Note_on_c, 0, 43, 100\n",
      "2, 2521, Note_on_c, 0, 50, 100\n",
      "2, 2521, Note_on_c, 0, 55, 100\n",
      "2, 3000, Note_on_c, 0, 43, 0\n",
      "2, 3000, Note_on_c, 0, 50, 0\n",
      "2, 3000, Note_on_c, 0, 55, 0\n",
      "2, 3001, Note_on_c, 0, 42, 100\n",
      "2, 3001, Note_on_c, 0, 51, 100\n",
      "2, 3001, Note_on_c, 0, 54, 100\n",
      "2, 3480, Note_on_c, 0, 42, 0\n",
      "2, 3480, Note_on_c, 0, 51, 0\n",
      "2, 3480, Note_on_c, 0, 54, 0\n",
      "2, 3481, Note_on_c, 0, 43, 100\n",
      "2, 3481, Note_on_c, 0, 50, 100\n",
      "2, 3481, Note_on_c, 0, 55, 100\n",
      "2, 3840, Note_on_c, 0, 55, 0\n",
      "2, 3841, Note_on_c, 0, 55, 100\n",
      "2, 3960, Note_on_c, 0, 55, 0\n",
      "2, 3961, Note_on_c, 0, 55, 100\n",
      "2, 4080, Note_on_c, 0, 55, 0\n",
      "2, 4081, Note_on_c, 0, 55, 100\n",
      "2, 4200, Note_on_c, 0, 55, 0\n",
      "2, 4201, Note_on_c, 0, 55, 100\n",
      "2, 4320, Note_on_c, 0, 55, 0\n",
      "2, 4321, Note_on_c, 0, 55, 100\n",
      "2, 4440, Note_on_c, 0, 55, 0\n",
      "2, 4441, Note_on_c, 0, 55, 100\n",
      "2, 4560, Note_on_c, 0, 55, 0\n",
      "2, 4561, Note_on_c, 0, 55, 100\n",
      "2, 4680, Note_on_c, 0, 55, 0\n",
      "2, 4681, Note_on_c, 0, 55, 100\n",
      "2, 4800, Note_on_c, 0, 43, 0\n",
      "2, 4800, Note_on_c, 0, 50, 0\n",
      "2, 4800, Note_on_c, 0, 55, 0\n",
      "2, 4801, Note_on_c, 0, 43, 100\n",
      "2, 4801, Note_on_c, 0, 50, 100\n",
      "2, 4801, Note_on_c, 0, 55, 100\n",
      "2, 4920, Note_on_c, 0, 43, 0\n",
      "2, 4920, Note_on_c, 0, 50, 0\n",
      "2, 4920, Note_on_c, 0, 55, 0\n",
      "2, 5281, Note_on_c, 0, 43, 100\n",
      "2, 5281, Note_on_c, 0, 50, 100\n",
      "2, 5281, Note_on_c, 0, 55, 100\n",
      "2, 5760, Note_on_c, 0, 43, 0\n",
      "2, 5760, Note_on_c, 0, 50, 0\n",
      "2, 5760, Note_on_c, 0, 55, 0\n",
      "2, 5761, Note_on_c, 0, 42, 100\n",
      "2, 5761, Note_on_c, 0, 51, 100\n",
      "2, 5761, Note_on_c, 0, 54, 100\n",
      "2, 6240, Note_on_c, 0, 42, 0\n",
      "2, 6240, Note_on_c, 0, 51, 0\n",
      "2, 6240, Note_on_c, 0, 54, 0\n",
      "2, 6241, Note_on_c, 0, 36, 100\n",
      "2, 6241, Note_on_c, 0, 38, 100\n",
      "2, 6241, Note_on_c, 0, 43, 100\n",
      "2, 6480, Note_on_c, 0, 36, 0\n",
      "2, 6480, Note_on_c, 0, 38, 0\n",
      "2, 6480, Note_on_c, 0, 43, 0\n",
      "2, 6481, Note_on_c, 0, 60, 100\n",
      "2, 6481, Note_on_c, 0, 48, 100\n",
      "2, 6720, Note_on_c, 0, 60, 0\n",
      "2, 6721, Note_on_c, 0, 60, 100\n",
      "2, 6800, Note_on_c, 0, 60, 0\n",
      "2, 6801, Note_on_c, 0, 60, 100\n",
      "2, 6880, Note_on_c, 0, 48, 0\n",
      "2, 6880, Note_on_c, 0, 60, 0\n",
      "2, 6881, Note_on_c, 0, 39, 100\n",
      "2, 6881, Note_on_c, 0, 50, 100\n",
      "2, 6881, Note_on_c, 0, 51, 100\n",
      "2, 6881, Note_on_c, 0, 57, 100\n",
      "2, 6881, Note_on_c, 0, 45, 100\n",
      "2, 7121, Note_on_c, 0, 38, 0\n",
      "2, 7121, Note_on_c, 0, 50, 0\n",
      "2, 7122, Note_on_c, 0, 31, 100\n",
      "2, 7122, Note_on_c, 0, 38, 100\n",
      "2, 7122, Note_on_c, 0, 43, 100\n",
      "2, 7361, Note_on_c, 0, 31, 0\n",
      "2, 7361, Note_on_c, 0, 38, 0\n",
      "2, 7361, Note_on_c, 0, 43, 0\n",
      "2, 7602, Note_on_c, 0, 39, 100\n",
      "2, 7602, Note_on_c, 0, 51, 100\n",
      "2, 7841, Note_on_c, 0, 39, 0\n",
      "2, 7841, Note_on_c, 0, 51, 0\n",
      "2, 8082, Note_on_c, 0, 55, 100\n",
      "2, 8321, Note_on_c, 0, 55, 0\n",
      "2, 8322, Note_on_c, 0, 49, 100\n",
      "2, 8322, Note_on_c, 0, 50, 100\n",
      "2, 8322, Note_on_c, 0, 52, 100\n",
      "2, 8801, Note_on_c, 0, 49, 0\n",
      "2, 8801, Note_on_c, 0, 50, 0\n",
      "2, 8801, Note_on_c, 0, 52, 0\n",
      "2, 8802, Note_on_c, 0, 43, 100\n",
      "2, 8802, Note_on_c, 0, 50, 100\n",
      "2, 8802, Note_on_c, 0, 55, 100\n",
      "2, 9281, Note_on_c, 0, 43, 0\n",
      "2, 9281, Note_on_c, 0, 50, 0\n",
      "2, 9281, Note_on_c, 0, 55, 0\n",
      "2, 9282, Note_on_c, 0, 43, 100\n",
      "2, 9282, Note_on_c, 0, 50, 100\n",
      "2, 9282, Note_on_c, 0, 55, 100\n",
      "2, 9761, Note_on_c, 0, 43, 0\n",
      "2, 9761, Note_on_c, 0, 50, 0\n",
      "2, 9761, Note_on_c, 0, 55, 0\n",
      "2, 9762, Note_on_c, 0, 42, 100\n",
      "2, 9762, Note_on_c, 0, 51, 100\n",
      "2, 9762, Note_on_c, 0, 54, 100\n",
      "2, 10241, Note_on_c, 0, 42, 0\n",
      "2, 10241, Note_on_c, 0, 51, 0\n",
      "2, 10241, Note_on_c, 0, 54, 0\n",
      "2, 10242, Note_on_c, 0, 43, 100\n",
      "2, 10242, Note_on_c, 0, 50, 100\n",
      "2, 10242, Note_on_c, 0, 55, 100\n",
      "2, 10482, Note_on_c, 0, 43, 0\n",
      "2, 10482, Note_on_c, 0, 50, 0\n",
      "2, 10482, Note_on_c, 0, 55, 0\n",
      "2, 10483, Note_on_c, 0, 44, 100\n",
      "2, 10483, Note_on_c, 0, 54, 100\n",
      "2, 10563, Note_on_c, 0, 55, 100\n",
      "2, 10642, Note_on_c, 0, 55, 0\n",
      "2, 10643, Note_on_c, 0, 55, 100\n",
      "2, 10722, Note_on_c, 0, 55, 0\n",
      "2, 10723, Note_on_c, 0, 55, 100\n",
      "2, 10802, Note_on_c, 0, 43, 0\n",
      "2, 10802, Note_on_c, 0, 55, 0\n",
      "2, 10803, Note_on_c, 0, 55, 100\n",
      "2, 10803, Note_on_c, 0, 43, 100\n",
      "2, 11042, Note_on_c, 0, 55, 0\n",
      "2, 11043, Note_on_c, 0, 55, 100\n",
      "2, 11163, Note_on_c, 0, 55, 100\n",
      "2, 11282, Note_on_c, 0, 55, 0\n",
      "2, 11283, Note_on_c, 0, 55, 100\n",
      "2, 11402, Note_on_c, 0, 55, 0\n",
      "2, 11403, Note_on_c, 0, 55, 100\n",
      "2, 11522, Note_on_c, 0, 55, 0\n",
      "2, 11523, Note_on_c, 0, 55, 100\n",
      "2, 11642, Note_on_c, 0, 55, 0\n",
      "2, 11643, Note_on_c, 0, 55, 100\n",
      "2, 11643, Note_on_c, 0, 57, 100\n",
      "2, 11643, Note_on_c, 0, 45, 100\n",
      "2, 12123, Note_on_c, 0, 37, 0\n",
      "2, 12123, Note_on_c, 0, 44, 0\n",
      "2, 12123, Note_on_c, 0, 49, 0\n",
      "2, 12124, Note_on_c, 0, 39, 100\n",
      "2, 12124, Note_on_c, 0, 46, 100\n",
      "2, 12124, Note_on_c, 0, 51, 100\n",
      "2, 12603, Note_on_c, 0, 39, 0\n",
      "2, 12603, Note_on_c, 0, 46, 0\n",
      "2, 12603, Note_on_c, 0, 51, 0\n",
      "2, 12604, Note_on_c, 0, 39, 100\n",
      "2, 12604, Note_on_c, 0, 46, 100\n",
      "2, 12604, Note_on_c, 0, 51, 100\n",
      "2, 13083, Note_on_c, 0, 39, 0\n",
      "2, 13083, Note_on_c, 0, 46, 0\n",
      "2, 13083, Note_on_c, 0, 51, 0\n",
      "2, 13084, Note_on_c, 0, 43, 100\n",
      "2, 13084, Note_on_c, 0, 50, 100\n",
      "2, 13084, Note_on_c, 0, 55, 100\n",
      "2, 13563, Note_on_c, 0, 43, 0\n",
      "2, 13563, Note_on_c, 0, 50, 0\n",
      "2, 13563, Note_on_c, 0, 55, 0\n",
      "2, 13564, Note_on_c, 0, 43, 100\n",
      "2, 13564, Note_on_c, 0, 50, 100\n",
      "2, 13564, Note_on_c, 0, 55, 100\n",
      "2, 14043, Note_on_c, 0, 43, 0\n",
      "2, 14043, Note_on_c, 0, 50, 0\n",
      "2, 14043, Note_on_c, 0, 55, 0\n",
      "2, 14044, Note_on_c, 0, 42, 100\n",
      "2, 14044, Note_on_c, 0, 51, 100\n",
      "2, 14044, Note_on_c, 0, 54, 100\n",
      "2, 14523, Note_on_c, 0, 42, 0\n",
      "2, 14523, Note_on_c, 0, 51, 0\n",
      "2, 14523, Note_on_c, 0, 54, 0\n",
      "2, 14524, Note_on_c, 0, 43, 100\n",
      "2, 14524, Note_on_c, 0, 50, 100\n",
      "2, 14524, Note_on_c, 0, 55, 100\n",
      "2, 14883, Note_on_c, 0, 55, 0\n",
      "2, 14884, Note_on_c, 0, 55, 100\n",
      "2, 15003, Note_on_c, 0, 55, 0\n",
      "2, 15004, Note_on_c, 0, 55, 100\n",
      "2, 15123, Note_on_c, 0, 55, 0\n",
      "2, 15124, Note_on_c, 0, 55, 100\n",
      "2, 15243, Note_on_c, 0, 55, 0\n",
      "2, 15244, Note_on_c, 0, 55, 100\n",
      "2, 15374, Note_on_c, 0, 49, 0\n",
      "2, 15374, Note_on_c, 0, 61, 0\n",
      "2, 15375, Note_on_c, 0, 48, 100\n",
      "2, 15375, Note_on_c, 0, 60, 100\n",
      "2, 15494, Note_on_c, 0, 48, 0\n",
      "2, 15494, Note_on_c, 0, 60, 0\n",
      "2, 15495, Note_on_c, 0, 43, 100\n",
      "2, 15495, Note_on_c, 0, 50, 100\n",
      "2, 15974, Note_on_c, 0, 43, 0\n",
      "2, 15974, Note_on_c, 0, 50, 0\n",
      "2, 15975, Note_on_c, 0, 39, 100\n",
      "2, 15975, Note_on_c, 0, 46, 100\n",
      "2, 16454, Note_on_c, 0, 39, 0\n",
      "2, 16454, Note_on_c, 0, 46, 0\n",
      "2, 16455, Note_on_c, 0, 43, 100\n",
      "2, 16455, Note_on_c, 0, 50, 100\n",
      "2, 16455, Note_on_c, 0, 55, 100\n",
      "2, 16814, Note_on_c, 0, 55, 0\n",
      "2, 16815, Note_on_c, 0, 55, 100\n",
      "2, 16934, Note_on_c, 0, 55, 0\n",
      "2, 16935, Note_on_c, 0, 55, 100\n",
      "2, 16936, Note_on_c, 0, 50, 0\n",
      "2, 17015, Note_on_c, 0, 55, 0\n",
      "2, 17016, Note_on_c, 0, 55, 100\n",
      "2, 17017, Note_on_c, 0, 43, 0\n"
     ]
    }
   ],
   "source": [
    "#back to original\n",
    "file = open(\"test.txt\",\"w\")\n",
    "#lines = file.read()\n",
    "#next line is the entire text file read\n",
    "#print(lines)\n",
    "splitLines = str(text_generated).split(' ')\n",
    "#print(splitLines)\n",
    "import copy\n",
    "time = []\n",
    "keys = []\n",
    "\n",
    "#print(len(splitLines))\n",
    "for i in range(0,len(splitLines)):\n",
    "    if splitLines[i].find(\"-\") == -1:\n",
    "        splitLines[i] = \"1-\" + splitLines[i]\n",
    "#    print(i)\n",
    "#    print(splitLines[i])\n",
    "    if i > 0 and splitLines[i][0:splitLines[i].find('-',0)] != '':\n",
    "        time.append(str(int(splitLines[i][0:splitLines[i].find('-',0)]) + int(time[i-1])))\n",
    "    else:\n",
    "        time.append(splitLines[i][0:splitLines[i].find('-',0)])\n",
    "    keys.append(splitLines[i][splitLines[i].find('-',0)+1:len(splitLines[i])])\n",
    "#    print(splitLines[i][0:splitLines[i].find('-',0)])\n",
    "#    print(splitLines[i][splitLines[i].find('-',0)+1:len(splitLines[i])])\n",
    "\n",
    "#print(time)\n",
    "#print(keys)\n",
    "\n",
    "for j in range(1,len(keys)):\n",
    "    prevLine = keys[j-1]\n",
    "    currLine = keys[j]\n",
    "    prevDict = {} \n",
    "    currDict = {}\n",
    "    for k in range(0,len(prevLine)):\n",
    "        if prevLine[k] in prevDict.keys():\n",
    "            prevDict[prevLine[k]] += 1\n",
    "        else:\n",
    "            prevDict[prevLine[k]] = 1\n",
    "    for m in range(0,len(currLine)):\n",
    "        if currLine[m] in currDict.keys():\n",
    "            currDict[currLine[m]] += 1\n",
    "        else:\n",
    "            currDict[currLine[m]] = 1\n",
    "    \n",
    "    prevDict1 = {}\n",
    "    for elements in prevDict.keys():\n",
    "        if elements in currDict.keys():\n",
    "            currDict.pop(elements)\n",
    "        elif elements not in currDict.keys():\n",
    "            prevDict1[elements] = prevDict[elements]\n",
    "#    print(time[j-1],\" \",prevDict1)\n",
    "#    print(time[j],\" \",currDict)\n",
    "    if len(prevDict1) == 0:\n",
    "        for things in currDict.keys():\n",
    "            print(\"2,\",time[j]+\", Note_on_c, 0,\",str(ord(things))+\", 100\")\n",
    "            file.write(\"2, \"+time[j]+\", Note_on_c, 0, \"+str(ord(things))+\", 100\"+\"\\n\")\n",
    "#        print(\"\\n\")\n",
    "    elif len(currDict) == 0:\n",
    "        for things in prevDict1.keys():\n",
    "            print(\"2,\",time[j]+\", Note_on_c, 0,\",str(ord(things))+\", 0\")\n",
    "            file.write(\"2, \"+time[j]+\", Note_on_c, 0, \"+str(ord(things))+\", 0\"+\"\\n\")\n",
    "#        print(\"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
